{"cells":[{"cell_type":"markdown","metadata":{"id":"SoOMF4kHSwMS"},"source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EzLpCjbDOZy_"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"sALkX2o9Syb_"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JFDOiKrSqVJ0"},"outputs":[],"source":["import os\n","import glob\n","import cv2\n","import json\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xn9z49K-CnXK"},"outputs":[],"source":["def get_image_and_json_paths(directory):\n","    image_paths = glob.glob(os.path.join(directory, '**', '*.jpg'), recursive=True)\n","    json_paths = glob.glob(os.path.join(directory, '**', '*.json'), recursive=True)\n","\n","    image_paths.sort()\n","    json_paths.sort()\n","\n","    return image_paths, json_paths\n","\n","\n","def crop_image(image, coordinates):\n","    if isinstance(coordinates, list):  # 다각형\n","        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n","        cv2.fillPoly(mask, [np.array(coordinates, np.int32)], (255))\n","        rect = cv2.boundingRect(np.array(coordinates, np.int32))\n","        cropped_image = cv2.bitwise_and(image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]], image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]], mask=mask[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]])\n","    else:  # 상자\n","        x, y, w, h = coordinates\n","        cropped_image = image[y:y + h, x:x + w]\n","    return cropped_image\n","\n","def process_images(image_paths, json_paths):\n","    cropped_images = []\n","    metadata_list = []\n","\n","    for image_path, json_path in zip(image_paths, json_paths):\n","        with open(json_path) as f:\n","            json_data = json.load(f)\n","\n","        image = cv2.imread(image_path)\n","\n","        if json_data.get('metaData'):\n","            metadata_list.append(json_data['metaData'])\n","\n","        if json_data.get('labelingInfo'):\n","            for label_info in json_data['labelingInfo']:\n","                if label_info.get('box'):\n","                    coordinates = label_info['box']\n","                    cropped_image = crop_image(image, coordinates)\n","                    cropped_images.append({\"cropped_box_image\": cropped_image})\n","                if label_info.get('polygon'):\n","                    coordinates = label_info['polygon']\n","                    cropped_image = crop_image(image, coordinates)\n","                    cropped_images.append({\"cropped_polygon_image\": cropped_image})\n","\n","    metadata_df = pd.DataFrame(metadata_list)\n","    cropped_images_df = pd.concat([pd.DataFrame(cropped_images[i]) for i in range(len(cropped_images))], keys=cropped_images, axis=1)\n","    images_metadata_df = pd.concat([metadata_df, cropped_images_df], axis=1)\n","\n","    return images_metadata_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-DCSQAmMqUX6"},"outputs":[],"source":["src_path = '/content/drive/Shareddrives/152.반려동물 피부질환 데이터'\n","image_paths, json_paths = get_image_and_json_paths(src_path)\n","result_df = process_images(image_paths, json_paths)\n","\n","result_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Q4RXaQOqUVh"},"outputs":[],"source":["# 메타데이터 개수 구하기\n","metadata_columns = len(result_df.columns) - 2\n","\n","# 1. 폴리곤 크롭 이미지\n","polygon_cropped = result_df.iloc[:, [-2]]\n","polygon_cropped.to_csv(\"polygon_cropped.csv\", index=False)\n","\n","# 2. 박스 크롭 이미지\n","box_cropped = result_df.iloc[:, [-1]]\n","box_cropped.to_csv(\"box_cropped.csv\", index=False)\n","\n","# 3. 폴리곤 크롭 이미지, 박스 크롭 이미지\n","polygon_box_cropped = result_df.iloc[:, [-2, -1]]\n","polygon_box_cropped.to_csv(\"polygon_box_cropped.csv\", index=False)\n","\n","# 4. 폴리곤 크롭 이미지, 메타데이터\n","polygon_cropped_metadata = result_df.iloc[:, list(range(metadata_columns)) + [-2]]\n","polygon_cropped_metadata.to_csv(\"polygon_cropped_metadata.csv\", index=False)\n","\n","# 5. 박스 크롭 이미지, 메타데이터\n","box_cropped_metadata = result_df.iloc[:, list(range(metadata_columns)) + [-1]]\n","box_cropped_metadata.to_csv(\"box_cropped_metadata.csv\", index=False)\n","\n","# 6. 폴리곤 크롭 이미지, 박스 크롭 이미지, 메타데이터\n","polygon_box_cropped_metadata = result_df.iloc[:, list(range(metadata_columns)) + [-2, -1]]\n","polygon_box_cropped_metadata.to_csv(\"polygon_box_cropped_metadata.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8AvPhlZ2qT5y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"auDavqpSS5rc"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PNTCTkPz0gx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eK7BGzioShjF"},"outputs":[],"source":["# 분류 모델과 하이퍼파라미터를 설정합니다\n","model_LR = LogisticRegression(random_state=9)\n","model_LDA = LinearDiscriminantAnalysis(solver='svd')\n","model_KNN = KNeighborsClassifier(n_neighbors=5)\n","model_DT = DecisionTreeClassifier(n_estimators=100)\n","model_RF = RandomForestClassifier(n_estimators=200, random_state=0)\n","model_GaussianNB = GaussianNB(var_smoothing=1e-09)\n","model_SVM = SVC(kernel='linear', C=1, random_state=0)\n","\n","# 분류 모델들을 리스트에 담습니다\n","models = [model_LR, model_LDA, model_KNN, model_DT, model_RF, model_GaussianNB, model_SVM]\n","\n","# 각 분류 모델을 학습시키고 예측 결과를 출력합니다\n","for model in models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    score = accuracy_score(y_test, y_pred)\n","    print(f\"{model.__class__.__name__}: {score}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZOVWv80Sea6"},"outputs":[],"source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# 첫번째 Conv2D 레이어\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# 첫번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 두번째 Conv2D 레이어\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 세번째 Conv2D 레이어\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 세번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# 첫번째 Dense 레이어\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.5))\n","\n","# 두번째 Dense 레이어: 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=val_data)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_data)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0qJBmnqSbr7"},"outputs":[],"source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOPxT6NNClFFGpPcs1OZu1y","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
