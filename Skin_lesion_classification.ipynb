{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPoSlL3wFr5RMjAqONtYSjl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"],"metadata":{"id":"SoOMF4kHSwMS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzLpCjbDOZy_","executionInfo":{"status":"ok","timestamp":1692164977527,"user_tz":-540,"elapsed":3104,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"cbd3655a-5417-47f7-f5fa-8044a262b606"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"sALkX2o9Syb_"}},{"cell_type":"code","source":["import cv2\n","import glob\n","import json\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","import re\n","\n","def get_image_data(src_path):\n","    image_paths = glob.glob(os.path.join(src_path, '**', '*.jpg'), recursive=True)\n","    image_paths.sort()\n","\n","    image_data = []\n","    for image_path in tqdm(image_paths, desc='Loading Images'):\n","        image = cv2.imread(image_path)\n","        image_data.append(image)\n","\n","    return image_data\n","\n","def get_data_info(src_path):\n","    json_paths = glob.glob(os.path.join(src_path, '**', '*.json'), recursive=True)\n","    json_paths.sort()\n","\n","    meta_data = []\n","    polygon_data = []\n","    box_data = []\n","\n","    for json_path in tqdm(json_paths, desc='Loading JSON', unit=' file'):\n","        with open(json_path, \"r\", encoding=\"utf-8\") as file:\n","            file_content = file.read()\n","            control_char_regex = r'[\\x00-\\x1F\\x7F-\\x9F]'\n","            cleaned_content = re.sub(control_char_regex, '', file_content)\n","            json_data = json.loads(cleaned_content)\n","            metadata = json_data.get('metaData', None)\n","\n","            filtered_metadata = {\n","                'breed': metadata.get('breed', None),\n","                'age': metadata.get('age', None),\n","                'gender': metadata.get('gender', None),\n","                'region': metadata.get('region', None),\n","                'species': metadata.get('species', None),\n","                'lesions': metadata.get('lesions', None),\n","                'polygon_location': [],\n","                'box_location': []\n","            }\n","\n","            labeling_info = json_data.get('labelingInfo', [])\n","\n","            for entry in labeling_info:\n","                if 'polygon' in entry:\n","                    polygon_metadata = filtered_metadata.copy()\n","                    polygon_metadata['polygon_location'] = entry['polygon'].get('location', None)\n","                    polygon_data.append(polygon_metadata)\n","                if 'box' in entry:\n","                    box_metadata = filtered_metadata.copy()\n","                    box_metadata['box_location'] = entry['box'].get('location', None)\n","                    box_data.append(box_metadata)\n","\n","            meta_data.append(filtered_metadata)\n","\n","    return meta_data, polygon_data, box_data\n","\n","def resize_image(image, width, height):\n","    tqdm.write(f'Resizing image from {image.shape[:2]} to {(width, height)}')\n","    resized_image = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n","    return resized_image\n","\n","def create_masks_maps(image, polygon_info, box_info):\n","    masks_map = np.zeros(image.shape[:2] + (4,), dtype=np.uint8)\n","\n","    for entry in tqdm(polygon_info, desc='Drawing Polygon'):\n","        loc = entry.get('polygon_location', [])\n","        fill_value = entry.get('lesions', 0) + 1\n","        if loc:\n","            polygon_points = np.array(loc, np.int32).reshape((-1, 1, 2))\n","            cv2.fillPoly(masks_map[..., 0], [polygon_points], 255)\n","            cv2.fillPoly(masks_map[..., 1], [polygon_points], fill_value)\n","\n","    for entry in tqdm(box_info, desc='Drawing Box'):\n","        loc = entry.get('box_location', [])\n","        fill_value = entry.get('lesions', 0) + 1\n","        if loc:\n","            cv2.rectangle(masks_map[..., 2], tuple(loc[:2]), tuple(loc[2:]), 255, thickness=-1)\n","            cv2.rectangle(masks_map[..., 3], tuple(loc[:2]), tuple(loc[2:]), fill_value, thickness=-1)\n","\n","    return masks_map\n","\n","def generate_masks_maps(image_data, polygon_data, box_data):\n","    masks_maps = []\n","    for data in tqdm(zip(image_data, polygon_data, box_data), desc='Generating Masks Maps'):\n","        masks_map = create_masks_maps(*data)\n","        masks_maps.append(masks_map)\n","    return masks_maps"],"metadata":{"id":"i7jwMMug2YXB","executionInfo":{"status":"ok","timestamp":1692166917951,"user_tz":-540,"elapsed":467,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["src_path = \"/content/drive/Shareddrives/152.반려동물 피부질환 데이터/validation/반려묘\""],"metadata":{"id":"yH2t11ewBsJe","executionInfo":{"status":"ok","timestamp":1692170813127,"user_tz":-540,"elapsed":300,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["image_data = get_image_data(src_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPE87bIUBtra","executionInfo":{"status":"ok","timestamp":1692150962169,"user_tz":-540,"elapsed":267968,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"e77b7146-660e-4f16-e6bc-ed5c7d20c8f8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading Images: 100%|██████████| 7219/7219 [04:23<00:00, 27.37it/s]\n"]}]},{"cell_type":"code","source":["meta_data, polygon_data, box_data = get_data_info(src_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"_mElvZXYBu9M","executionInfo":{"status":"error","timestamp":1692151035880,"user_tz":-540,"elapsed":3145,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"bcc4f668-8130-4b8d-c797-28b6f23b981b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Loading JSON:   4%|▍         | 312/7220 [00:01<00:39, 177.09 file/s]\n"]},{"output_type":"error","ename":"JSONDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0c347272566f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolygon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-507f294118d0>\u001b[0m in \u001b[0;36mget_data_info\u001b[0;34m(src_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metaData'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"]}]},{"cell_type":"code","source":["masks_maps = generate_masks_maps(image_data, polygon_data, box_data)"],"metadata":{"id":"qM9RIIj2Bv66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9iqtx8ZYO06J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0zPJEzzCuVy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Before_Resize_Polygon_Binary_Mask.csv\n","After_Resize_Polygon_Binary_Mask.csv\n","Before_Resize_Box_Binary_Mask.csv\n","After_Resize_Box_Binary_Mask.csv\n","Before_Resize_Polygon_Segmentation_Map.csv\n","After_Resize_Polygon_Segmentation_Map.csv\n","Before_Resize_Box_Segmentation_Map.csv\n","After_Resize_Box_Segmentation_Map.csv\n","Before_Resize_Polygon_Box_Binary_Mask.csv\n","After_Resize_Polygon_Box_Binary_Mask.csv\n","Before_Resize_Polygon_Box_Segmentation_Map.csv\n","After_Resize_Polygon_Box_Segmentation_Map.csv\n","Before_Resize_Polygon_Binary_Mask_MetaData.csv\n","After_Resize_Polygon_Binary_Mask_MetaData.csv\n","Before_Resize_Box_Binary_Mask_MetaData.csv\n","After_Resize_Box_Binary_Mask_MetaData.csv\n","Before_Resize_Polygon_Segmentation_Map_MetaData.csv\n","After_Resize_Polygon_Segmentation_Map_MetaData.csv\n","Before_Resize_Box_Segmentation_Map_MetaData.csv\n","After_Resize_Box_Segmentation_Map_MetaData.csv"],"metadata":{"id":"CsVelS76GYKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"auDavqpSS5rc"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"9KN24A9E1JFc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s4QcwK9UBb2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 분류 모델과 하이퍼파라미터를 설정합니다\n","model_LR = LogisticRegression(random_state=9)\n","model_LDA = LinearDiscriminantAnalysis(solver='svd')\n","model_KNN = KNeighborsClassifier(n_neighbors=5)\n","model_DT = DecisionTreeClassifier(n_estimators=100)\n","model_RF = RandomForestClassifier(n_estimators=200, random_state=0)\n","model_GaussianNB = GaussianNB(var_smoothing=1e-09)\n","model_SVM = SVC(kernel='linear', C=1, random_state=0)\n","\n","# 분류 모델들을 리스트에 담습니다\n","models = [model_LR, model_LDA, model_KNN, model_DT, model_RF, model_GaussianNB, model_SVM]\n","\n","# 각 분류 모델을 학습시키고 예측 결과를 출력합니다\n","for model in models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    score = accuracy_score(y_test, y_pred)\n","    print(f\"{model.__class__.__name__}: {score}\")"],"metadata":{"id":"eK7BGzioShjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KutoBNj2_Iuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# 첫번째 Conv2D 레이어\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# 첫번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 두번째 Conv2D 레이어\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 세번째 Conv2D 레이어\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 세번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# 첫번째 Dense 레이어\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.5))\n","\n","# 두번째 Dense 레이어: 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=val_data)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_data)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"IZOVWv80Sea6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EG-vxlAj_HYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"f0qJBmnqSbr7"},"execution_count":null,"outputs":[]}]}