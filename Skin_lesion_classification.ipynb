{"cells":[{"cell_type":"markdown","metadata":{"id":"SoOMF4kHSwMS"},"source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3351,"status":"ok","timestamp":1694153489191,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"EzLpCjbDOZy_","outputId":"0b1c1e46-ce21-4bf9-8ba2-8472caa8215e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import glob\n","import json\n","import cv2\n","import numpy as np\n","from skimage.feature import graycomatrix\n","import h5py\n","\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc"],"metadata":{"id":"491U9sI3TVVj","executionInfo":{"status":"ok","timestamp":1694153492721,"user_tz":-540,"elapsed":3533,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def get_path_and_lable(src_path, num_files_per_folder):\n","    image_paths = []\n","    lesions = []\n","\n","    for root, dirs, files in tqdm(os.walk(src_path), desc='Walking directories', unit=' dir'):\n","        for dir in dirs:\n","            dir_path = os.path.join(root, dir)\n","            image_files = sorted(glob.glob(os.path.join(dir_path, '*.jpg')))\n","\n","            for image_file in image_files[:num_files_per_folder]:\n","                filename = os.path.basename(image_file)\n","                parts = filename.split('_')\n","                if len(parts) >= 3:\n","                    second_part = parts[2]\n","                    lesions.append(second_part)\n","                    image_paths.append(image_file)\n","\n","    return image_paths, lesions\n","\n","class ImageFeatureExtractor:\n","    def __init__(self, target_size):\n","        self.target_size = target_size\n","\n","    def preprocess_image(self, image_path):\n","        image = cv2.imread(image_path)\n","        image = cv2.resize(image, self.target_size)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        return image\n","\n","    def extract_color_histogram(self, image):\n","        histogram = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n","        histogram = cv2.normalize(histogram, histogram).flatten()\n","        return histogram\n","\n","    def extract_hu_moments(self, image):\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","        moments = cv2.HuMoments(cv2.moments(gray_image)).flatten()\n","        return moments\n","\n","    def extract_haralick_texture(self, image):\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","        texture = graycomatrix(gray_image, distances=[1], angles=[0], symmetric=True, normed=True)\n","        haralick_features = np.mean(texture, axis=(0, 1, 2))\n","        return haralick_features\n","\n","    def extract_features(self, image_path):\n","        image = self.preprocess_image(image_path)\n","        color_histogram = self.extract_color_histogram(image)\n","        hu_moments = self.extract_hu_moments(image)\n","        haralick_texture = self.extract_haralick_texture(image)\n","        global_features = np.concatenate([color_histogram, hu_moments, haralick_texture])\n","        return global_features\n","\n","    def save_features_to_hdf5(self, features, lesions, output_path):\n","        with h5py.File(output_path, 'w') as f:\n","            f.create_dataset('features', data=features)\n","            f.create_dataset('lesions', data=lesions)\n","\n","def load_data_from_hdf5(file_path):\n","    with h5py.File(file_path, 'r') as f:\n","        features = f['features'][:]\n","        lesions = f['lesions'][:]\n","    return features, lesions"],"metadata":{"id":"qEuSRFdOTKoU","executionInfo":{"status":"ok","timestamp":1694153492722,"user_tz":-540,"elapsed":9,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sALkX2o9Syb_"},"source":["# camera cat"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3480,"status":"ok","timestamp":1694153572971,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"yH2t11ewBsJe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cbe5ea12-82f7-4c87-ed6b-f8282166a919"},"outputs":[{"output_type":"stream","name":"stderr","text":["Walking directories: 15 dir [00:02,  5.29 dir/s]\n"]}],"source":["src_path = '/content/drive/Shareddrives/반려묘/일반카메라'\n","num_files_per_folder = 1000\n","buffer_size = 1000\n","batch_size = 64\n","target_size = (96, 96)\n","\n","image_paths, lesions = get_path_and_lable(src_path, num_files_per_folder)\n","lesions = np.array([s.encode('utf-8') for s in lesions])"]},{"cell_type":"code","source":["feature_extractor = ImageFeatureExtractor(target_size=(96, 96))\n","\n","features = []\n","for image_path in tqdm(image_paths):\n","    image_features = feature_extractor.extract_features(image_path)\n","    features.append(image_features)\n","\n","features = np.array(features)\n","lesions = np.array(lesions)\n","\n","output_path = 'features.h5'\n","feature_extractor.save_features_to_hdf5(features, lesions, output_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AP9hy-9_CyBe","executionInfo":{"status":"ok","timestamp":1694153872251,"user_tz":-540,"elapsed":299285,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"05cbe88e-0b57-4fef-9cab-388b6697b9d1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10675/10675 [04:59<00:00, 35.59it/s]\n"]}]},{"cell_type":"code","source":["hdf5_file_path = 'features.h5'\n","\n","features, lesions = load_data_from_hdf5(hdf5_file_path)\n","\n","X_train, X_test, y_train, y_test = train_test_split(features, lesions, test_size=0.2, random_state=42)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"],"metadata":{"id":"23mCdag7SVAd","executionInfo":{"status":"ok","timestamp":1694153959383,"user_tz":-540,"elapsed":1016,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(96, 96, 3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","model.add(Conv2D(64,(3 ,3), padding ='same', activation ='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2 , 2)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128,(3 ,3), padding ='same', activation ='relu'))\n","model.add(Conv2D(128,(3 ,3), padding ='same', activation ='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size =(2 , 2)))\n","\n","model.add(Dropout (0.25))\n","\n","model.add(Flatten())\n","\n","model.add(Dense (1024 ,activation = 'relu' ))\n","model.add(BatchNormalization ())\n","Model.add(Dropout (0.5 ))\n","\n","Model.add(Dense (4 ,activation = 'softmax' ))\n","\n","opt = Adam(learning_rate=0.001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])"],"metadata":{"id":"JGUbxOe3TxF0","executionInfo":{"status":"ok","timestamp":1694153964620,"user_tz":-540,"elapsed":1491,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs=150, batch_size=32, validation_data=(X_val, y_val))"],"metadata":{"id":"2iSRx9X0aFUi","colab":{"base_uri":"https://localhost:8080/","height":627},"outputId":"a5e055cd-3204-4cb9-9a9b-6da8a42ba57a","executionInfo":{"status":"error","timestamp":1694154159921,"user_tz":-540,"elapsed":1053,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a09c68e64ef0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(None, 520)\n"]}]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(y_test, axis=1)\n","\n","print(classification_report(y_true_classes, y_pred_classes))"],"metadata":{"id":"_QCLXIZcTyct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()"],"metadata":{"id":"J-bU50bZECY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","for i in range(4):\n","    fpr[i], tpr[i], _ = roc_curve(y_true_classes, y_pred[:, i], pos_label=i)\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","plt.figure(figsize=(8, 6))\n","for i in range(4):\n","    plt.plot(fpr[i], tpr[i], lw=2, label=f'ROC curve (class {i}, AUC = {roc_auc[i:.2f})')\n","\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc='lower right')\n","plt.show()"],"metadata":{"id":"d2wLTowRD_4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('Mk-1.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"s7f5CnkuvE2g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EeLaIH1wZTsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qqg4JHS0Y_yH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# microscope cat"],"metadata":{"id":"5St-XgMdS3A_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZOVWv80Sea6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG-vxlAj_HYD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0qJBmnqSbr7"},"outputs":[],"source":["from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import MeanSquaredError\n","from tensorflow.keras.layers import Concatenate, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.losses import mean_squared_error\n","\n","def inception_module(input_layer, filters):\n","    conv1x1 = Conv2D(filters[0], (1, 1), activation='relu')(input_layer)\n","    conv3x3_reduce = Conv2D(filters[1], (1, 1), activation='relu')(input_layer)\n","    conv3x3 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(conv3x3_reduce)\n","    conv5x5_reduce = Conv2D(filters[3], (1, 1), activation='relu')(input_layer)\n","    conv5x5 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(conv5x5_reduce)\n","    maxpool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_layer)\n","    maxpool_conv = Conv2D(filters[5], (1, 1), activation='relu')(maxpool)\n","    inception_output = Concatenate(axis=-1)([conv1x1, conv3x3, conv5x5, maxpool_conv])\n","    return inception_output\n","\n","# Input\n","input_shape = (128, 128, 3)\n","input_layer = Input(shape=input_shape)\n","\n","# Inception block\n","inception_output = inception_module(input_layer, filters=[64, 128, 192, 32, 96, 64])\n","inception_output = inception_module(inception_output, filters=[64, 128, 192, 32, 96, 64])\n","# Add more inception modules if needed\n","\n","# Primary Capsule layer\n","primary_capsules = Conv2D(32, (1, 1), activation='relu')(inception_output)\n","\n","# Higher Capsule layers\n","# (Add imperative routing mechanism layers here)\n","\n","# PReLU activation for routing\n","higher_capsules_prelu = PReLU()(higher_capsules)\n","\n","# Flatten and Fully Connected layers\n","capsule_flatten = Flatten()(higher_capsules_prelu)  # Flatten higher capsules\n","output_layer = Dense(2, activation='softmax')(capsule_flatten)  # Two capsules: parasitized and uninfected\n","\n","# Create the model\n","model = Model(inputs=input_layer, outputs=output_layer)\n","\n","# Compile the model with Adam optimizer and custom loss function\n","optimizer = Adam(learning_rate=0.007, beta_1=0.8)\n","loss_fn = custom_loss_function # Define the custom loss function as described in the paper\n","model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","mount_file_id":"1Dnsl078JzGwH-snRqYpe4v_RDBNGZeJb","authorship_tag":"ABX9TyP1+uNGbDtsT1u1L2JUd6rJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}