{"cells":[{"cell_type":"markdown","metadata":{"id":"SoOMF4kHSwMS"},"source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3183,"status":"ok","timestamp":1693286269266,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"EzLpCjbDOZy_","outputId":"e8431783-c049-4a7f-bfc2-b15704ff9cc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import cv2\n","import glob\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import re\n","import tensorflow as tf\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import models\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tqdm import tqdm"],"metadata":{"id":"491U9sI3TVVj","executionInfo":{"status":"ok","timestamp":1693286272339,"user_tz":-540,"elapsed":3076,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def get_image_and_json_paths(src_path):\n","    image_paths = sorted(glob.glob(os.path.join(src_path, '**', '*.jpg'), recursive=True))\n","    json_paths = sorted(glob.glob(os.path.join(src_path, '**', '*.json'), recursive=True))\n","\n","    return image_paths, json_paths\n","\n","def extract_metadata_and_locations_from_json(json_paths):\n","    meta_data, polygon_data, box_data = [], [], []\n","    for json_path in tqdm(json_paths, desc='Loading JSON', unit=' file'):\n","        try:\n","            with open(json_path, 'r', encoding='utf-8') as file:\n","                json_data = json.loads(re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', file.read()))\n","                labeling_info, metadata = json_data['labelingInfo'], json_data.get('metaData', None)\n","\n","                filtered_metadata = {\n","                    'breed': metadata.get('breed', None),\n","                    'age': metadata.get('age', None),\n","                    'gender': metadata.get('gender', None),\n","                    'region': metadata.get('region', None),\n","                    'lesions': metadata.get('lesions', None)\n","                }\n","\n","                meta_data.append(filtered_metadata)\n","\n","                for entry in labeling_info:\n","                    if 'polygon' in entry:\n","                        polygon_data.extend(entry['polygon'].get('location', []))\n","                    if 'box' in entry:\n","                        box_data.extend(entry['box'].get('location', []))\n","\n","        except Exception as e:\n","            print(json_path)\n","            print(e)\n","\n","    return meta_data, polygon_data, box_data\n","\n","def combine_images_and_masks(image_list, mask_list):\n","    combined_images = []\n","\n","    for i in tqdm(range(len(image_list)), desc='Combining Images and Masks'):\n","        image = image_list[i]\n","        mask = mask_list[i]\n","\n","        # Create an empty mask channel with the same shape as the image\n","        mask_channel = np.zeros_like(image[:, :, 0], dtype=np.uint8)\n","\n","        # Set the mask channel to the mask values\n","        mask_channel[mask == 1] = 255\n","\n","        # Stack the mask channel with the image\n","        combined_image = np.dstack((image, mask_channel))\n","\n","        combined_images.append(combined_image)\n","\n","    return combined_images\n","\n","def one_hot_encode_labels(labels):\n","    label_binarizer = LabelBinarizer()\n","    encoded_labels = label_binarizer.fit_transform(labels)\n","    return np.array(encoded_labels), label_binarizer\n","\n","def create_polygon_binary_masks(image_list, polygon_data_list):\n","    binary_masks = []\n","\n","    for image, polygon_data in tqdm(zip(image_list, polygon_data_list), desc='Generating Binary Masks', total=len(image_list)):\n","        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n","\n","        for poly_coords in polygon_data:\n","            if poly_coords:\n","                poly_points = []\n","                i = 1\n","                while f'x{i}' in poly_coords and f'y{i}' in poly_coords:\n","                    x = poly_coords[f'x{i}']\n","                    y = poly_coords[f'y{i}']\n","                    poly_points.append([x, y])\n","                    i += 1\n","                if len(poly_points) > 0:\n","                    poly_points = np.array(poly_points, dtype=np.int32)\n","                    cv2.fillPoly(mask, [poly_points], 255)\n","            print(poly_coords)\n","\n","        binary_masks.append(mask)\n","\n","    return binary_masks\n","\n","def visualize_masks(image_data, mask_data, selected_indices, figsize=(10, 5)):\n","    for idx in selected_indices:\n","        image = image_data[idx]\n","        mask_map = mask_data[idx]\n","\n","        plt.figure(figsize=figsize)\n","        plt.subplot(1, mask_map.shape[2] + 1, 1)\n","        plt.imshow(image)\n","        plt.title('Original Image')\n","\n","        for ch in range(mask_map.shape[2]):\n","            plt.subplot(1, mask_map.shape[2] + 1, ch + 2)\n","            plt.imshow(mask_map[:, :, ch], cmap='gray')\n","            plt.title(f'Channel {ch}')\n","\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"qEuSRFdOTKoU","executionInfo":{"status":"ok","timestamp":1693286272339,"user_tz":-540,"elapsed":3,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sALkX2o9Syb_"},"source":["# camera cat"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1693286272339,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"yH2t11ewBsJe"},"outputs":[],"source":["src_path = '/content/drive/Shareddrives/반려묘/일반카메라'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":508,"status":"ok","timestamp":1693286272845,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"8tKyLk1IGIEw"},"outputs":[],"source":["image_paths, json_paths = get_image_and_json_paths(src_path)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4510,"status":"ok","timestamp":1693286277353,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"_EHfOaAWGRRY","outputId":"c972790d-ea01-440f-f860-6340a7d826e9"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading JSON: 100%|██████████| 5500/5500 [00:04<00:00, 1206.40 file/s]\n"]}],"source":["meta_data, polygon_data, box_data = extract_metadata_and_locations_from_json(json_paths)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MlalA8N-GMSd","executionInfo":{"status":"ok","timestamp":1693286277354,"user_tz":-540,"elapsed":5,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"outputs":[],"source":["metadata_df = pd.DataFrame(meta_data)\n","metadata_df['image_paths'] = image_paths"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1693286277354,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"ZQ90HinzOLeE","outputId":"62e1e229-633c-47a8-a3a3-4f3c0917b1cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       breed age gender region lesions  \\\n","0      노르웨이숲  10      M      H      A7   \n","1      노르웨이숲  10      M      B      A7   \n","2      노르웨이숲   4      M      B      A7   \n","3      노르웨이숲  10      F      B      A7   \n","4      노르웨이숲  10      F      B      A7   \n","...      ...  ..    ...    ...     ...   \n","5495    페르시안   2      F      L      A6   \n","5496  코리안숏헤어   8      F      H      A6   \n","5497  코리안숏헤어   5      M      H      A6   \n","5498  코리안숏헤어   2      F      H      A6   \n","5499  코리안숏헤어   1      M      L      A6   \n","\n","                                            image_paths  \n","0     /content/drive/Shareddrives/반려묘/일반카메라/무증상...  \n","1     /content/drive/Shareddrives/반려묘/일반카메라/무증상...  \n","2     /content/drive/Shareddrives/반려묘/일반카메라/무증상...  \n","3     /content/drive/Shareddrives/반려묘/일반카메라/무증상...  \n","4     /content/drive/Shareddrives/반려묘/일반카메라/무증상...  \n","...                                                 ...  \n","5495  /content/drive/Shareddrives/반려묘/일반카메라/유증상...  \n","5496  /content/drive/Shareddrives/반려묘/일반카메라/유증상...  \n","5497  /content/drive/Shareddrives/반려묘/일반카메라/유증상...  \n","5498  /content/drive/Shareddrives/반려묘/일반카메라/유증상...  \n","5499  /content/drive/Shareddrives/반려묘/일반카메라/유증상...  \n","\n","[5500 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-919098b2-ba9f-4cfe-9acf-6a409593d2da\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>breed</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>region</th>\n","      <th>lesions</th>\n","      <th>image_paths</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>M</td>\n","      <td>H</td>\n","      <td>A7</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>A7</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>노르웨이숲</td>\n","      <td>4</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>A7</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>A7</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>A7</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5495</th>\n","      <td>페르시안</td>\n","      <td>2</td>\n","      <td>F</td>\n","      <td>L</td>\n","      <td>A6</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","    </tr>\n","    <tr>\n","      <th>5496</th>\n","      <td>코리안숏헤어</td>\n","      <td>8</td>\n","      <td>F</td>\n","      <td>H</td>\n","      <td>A6</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","    </tr>\n","    <tr>\n","      <th>5497</th>\n","      <td>코리안숏헤어</td>\n","      <td>5</td>\n","      <td>M</td>\n","      <td>H</td>\n","      <td>A6</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","    </tr>\n","    <tr>\n","      <th>5498</th>\n","      <td>코리안숏헤어</td>\n","      <td>2</td>\n","      <td>F</td>\n","      <td>H</td>\n","      <td>A6</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","    </tr>\n","    <tr>\n","      <th>5499</th>\n","      <td>코리안숏헤어</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>L</td>\n","      <td>A6</td>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5500 rows × 6 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-919098b2-ba9f-4cfe-9acf-6a409593d2da')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-919098b2-ba9f-4cfe-9acf-6a409593d2da button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-919098b2-ba9f-4cfe-9acf-6a409593d2da');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-82efd869-33a4-407f-a19b-95fb7899432f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82efd869-33a4-407f-a19b-95fb7899432f')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-82efd869-33a4-407f-a19b-95fb7899432f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}],"source":["metadata_df"]},{"cell_type":"code","source":["datagen = ImageDataGenerator(\n","    rescale = 1.0/255,\n","    rotation_range = 20,\n","    width_shift_range = 0.2,\n","    height_shift_range = 0.2,\n","    shear_range = 0.2,\n","    zoom_range = 0.2,\n","    horizontal_flip = True,\n","    fill_mode = 'nearest'\n",")"],"metadata":{"id":"rCDslFuU79Ds","executionInfo":{"status":"ok","timestamp":1693286277989,"user_tz":-540,"elapsed":2,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_df, temp_df = train_test_split(metadata_df, test_size=0.2, random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"],"metadata":{"id":"O7m1-ZfmV-01","executionInfo":{"status":"ok","timestamp":1693286279340,"user_tz":-540,"elapsed":3,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_generator = datagen.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='image_paths',\n","    y_col='lesions',\n","    class_mode='categorical',\n","    target_size=(96, 96),\n","    batch_size=32\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1IU9hs473GM","executionInfo":{"status":"ok","timestamp":1693286281285,"user_tz":-540,"elapsed":529,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"ae34c41c-c261-465b-81ba-545136718e62"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4400 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["val_generator = datagen.flow_from_dataframe(\n","    dataframe=val_df,\n","    x_col='image_paths',\n","    y_col='lesions',\n","    class_mode='categorical',\n","    target_size=(96, 96),\n","    batch_size=32\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hS9LF1g3U3cu","executionInfo":{"status":"ok","timestamp":1693286282772,"user_tz":-540,"elapsed":496,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"7d02def5-4ac3-4be7-89cf-b0bef51556b6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 550 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["test_generator = datagen.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='image_paths',\n","    y_col='lesions',\n","    class_mode='categorical',\n","    target_size=(96, 96),\n","    batch_size=32,\n","    shuffle=False\n",")"],"metadata":{"id":"mXLi75CKV3Mk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693286283636,"user_tz":-540,"elapsed":5,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"ee6aad7c-0998-4eeb-ee3f-962d3c7b8d65"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 550 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["model = models.Sequential()\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(units=4, activation='softmax'))\n","\n","opt = Adam(learning_rate=0.001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])"],"metadata":{"id":"JGUbxOe3TxF0","executionInfo":{"status":"ok","timestamp":1693286287012,"user_tz":-540,"elapsed":1632,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["history1 = model.fit(\n","    train_generator,\n","    epochs=150,\n","    batch_size=32,\n","    validation_data=val_generator\n",")"],"metadata":{"id":"2iSRx9X0aFUi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b33ffa8-ce09-4cf6-889a-fb301f8b8951"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","138/138 [==============================] - 78s 510ms/step - loss: 1.6290 - accuracy: 0.4693 - val_loss: 1.4930 - val_accuracy: 0.5618\n","Epoch 2/150\n","138/138 [==============================] - 71s 516ms/step - loss: 1.2807 - accuracy: 0.5418 - val_loss: 1.6258 - val_accuracy: 0.2782\n","Epoch 3/150\n","138/138 [==============================] - 71s 512ms/step - loss: 1.2126 - accuracy: 0.5564 - val_loss: 1.3351 - val_accuracy: 0.6055\n","Epoch 4/150\n","138/138 [==============================] - 70s 508ms/step - loss: 1.1764 - accuracy: 0.5580 - val_loss: 1.3600 - val_accuracy: 0.4927\n","Epoch 5/150\n","138/138 [==============================] - 70s 511ms/step - loss: 1.0821 - accuracy: 0.5841 - val_loss: 0.9237 - val_accuracy: 0.6309\n","Epoch 6/150\n","138/138 [==============================] - 70s 508ms/step - loss: 1.0631 - accuracy: 0.6025 - val_loss: 0.9204 - val_accuracy: 0.6509\n","Epoch 7/150\n","138/138 [==============================] - 70s 505ms/step - loss: 1.0703 - accuracy: 0.5995 - val_loss: 0.9844 - val_accuracy: 0.6455\n","Epoch 8/150\n","138/138 [==============================] - 70s 508ms/step - loss: 1.0033 - accuracy: 0.6234 - val_loss: 1.6543 - val_accuracy: 0.4218\n","Epoch 9/150\n","138/138 [==============================] - 70s 509ms/step - loss: 0.9919 - accuracy: 0.6257 - val_loss: 1.5026 - val_accuracy: 0.4618\n","Epoch 10/150\n","138/138 [==============================] - 71s 515ms/step - loss: 0.9644 - accuracy: 0.6277 - val_loss: 0.9216 - val_accuracy: 0.6436\n","Epoch 11/150\n","138/138 [==============================] - 69s 504ms/step - loss: 0.9657 - accuracy: 0.6302 - val_loss: 0.9501 - val_accuracy: 0.6400\n","Epoch 12/150\n","138/138 [==============================] - 71s 512ms/step - loss: 0.9896 - accuracy: 0.6195 - val_loss: 0.9351 - val_accuracy: 0.6509\n","Epoch 13/150\n","138/138 [==============================] - 71s 512ms/step - loss: 0.9487 - accuracy: 0.6373 - val_loss: 0.9179 - val_accuracy: 0.6255\n","Epoch 14/150\n","138/138 [==============================] - 71s 513ms/step - loss: 0.9501 - accuracy: 0.6357 - val_loss: 1.0682 - val_accuracy: 0.6000\n","Epoch 15/150\n","138/138 [==============================] - 70s 507ms/step - loss: 0.9367 - accuracy: 0.6407 - val_loss: 1.5401 - val_accuracy: 0.5982\n","Epoch 16/150\n","138/138 [==============================] - 70s 511ms/step - loss: 0.9302 - accuracy: 0.6441 - val_loss: 1.7845 - val_accuracy: 0.4218\n","Epoch 17/150\n","138/138 [==============================] - 70s 508ms/step - loss: 0.9289 - accuracy: 0.6473 - val_loss: 1.1130 - val_accuracy: 0.6218\n","Epoch 18/150\n","138/138 [==============================] - 70s 510ms/step - loss: 0.9218 - accuracy: 0.6482 - val_loss: 1.4259 - val_accuracy: 0.5891\n","Epoch 19/150\n","138/138 [==============================] - 71s 515ms/step - loss: 0.9274 - accuracy: 0.6511 - val_loss: 1.0159 - val_accuracy: 0.5855\n","Epoch 20/150\n","138/138 [==============================] - 70s 504ms/step - loss: 0.9162 - accuracy: 0.6464 - val_loss: 0.9354 - val_accuracy: 0.6509\n","Epoch 21/150\n","138/138 [==============================] - 70s 508ms/step - loss: 0.8854 - accuracy: 0.6645 - val_loss: 1.1053 - val_accuracy: 0.5727\n","Epoch 22/150\n","138/138 [==============================] - 69s 499ms/step - loss: 0.9126 - accuracy: 0.6541 - val_loss: 1.0914 - val_accuracy: 0.5618\n","Epoch 23/150\n","138/138 [==============================] - 71s 514ms/step - loss: 0.9109 - accuracy: 0.6514 - val_loss: 1.4950 - val_accuracy: 0.5618\n","Epoch 24/150\n","138/138 [==============================] - 71s 512ms/step - loss: 0.9003 - accuracy: 0.6598 - val_loss: 1.0713 - val_accuracy: 0.6055\n","Epoch 25/150\n","138/138 [==============================] - 71s 512ms/step - loss: 0.8957 - accuracy: 0.6559 - val_loss: 1.0711 - val_accuracy: 0.6764\n","Epoch 26/150\n","138/138 [==============================] - 70s 509ms/step - loss: 0.8919 - accuracy: 0.6589 - val_loss: 2.1034 - val_accuracy: 0.5600\n","Epoch 27/150\n","138/138 [==============================] - 70s 510ms/step - loss: 0.8787 - accuracy: 0.6720 - val_loss: 0.8750 - val_accuracy: 0.6673\n","Epoch 28/150\n","138/138 [==============================] - 70s 507ms/step - loss: 0.8737 - accuracy: 0.6702 - val_loss: 0.8533 - val_accuracy: 0.6764\n","Epoch 29/150\n","138/138 [==============================] - 70s 510ms/step - loss: 0.8675 - accuracy: 0.6641 - val_loss: 1.2457 - val_accuracy: 0.6182\n","Epoch 30/150\n","138/138 [==============================] - 71s 513ms/step - loss: 0.8845 - accuracy: 0.6600 - val_loss: 1.2838 - val_accuracy: 0.5000\n","Epoch 31/150\n","138/138 [==============================] - 71s 516ms/step - loss: 0.8632 - accuracy: 0.6664 - val_loss: 1.5788 - val_accuracy: 0.4836\n","Epoch 32/150\n","138/138 [==============================] - 71s 516ms/step - loss: 0.8452 - accuracy: 0.6686 - val_loss: 0.8825 - val_accuracy: 0.6836\n","Epoch 33/150\n","138/138 [==============================] - 71s 514ms/step - loss: 0.8503 - accuracy: 0.6707 - val_loss: 1.2390 - val_accuracy: 0.5055\n","Epoch 34/150\n","138/138 [==============================] - 70s 509ms/step - loss: 0.8488 - accuracy: 0.6789 - val_loss: 1.2836 - val_accuracy: 0.6545\n","Epoch 35/150\n","138/138 [==============================] - 70s 508ms/step - loss: 0.8628 - accuracy: 0.6709 - val_loss: 1.8735 - val_accuracy: 0.5673\n","Epoch 36/150\n","138/138 [==============================] - 71s 511ms/step - loss: 0.8477 - accuracy: 0.6752 - val_loss: 1.4325 - val_accuracy: 0.6182\n","Epoch 37/150\n","138/138 [==============================] - 70s 509ms/step - loss: 0.8509 - accuracy: 0.6720 - val_loss: 0.8378 - val_accuracy: 0.6691\n","Epoch 38/150\n","138/138 [==============================] - 70s 507ms/step - loss: 0.8421 - accuracy: 0.6732 - val_loss: 1.0005 - val_accuracy: 0.6473\n","Epoch 39/150\n","138/138 [==============================] - 70s 510ms/step - loss: 0.8482 - accuracy: 0.6707 - val_loss: 0.9111 - val_accuracy: 0.6455\n","Epoch 40/150\n","138/138 [==============================] - 72s 526ms/step - loss: 0.8505 - accuracy: 0.6723 - val_loss: 0.9644 - val_accuracy: 0.6236\n","Epoch 41/150\n","138/138 [==============================] - 71s 514ms/step - loss: 0.8008 - accuracy: 0.6984 - val_loss: 0.9176 - val_accuracy: 0.6691\n","Epoch 42/150\n","138/138 [==============================] - 70s 510ms/step - loss: 0.8320 - accuracy: 0.6759 - val_loss: 1.0962 - val_accuracy: 0.6327\n","Epoch 43/150\n","138/138 [==============================] - 71s 517ms/step - loss: 0.8308 - accuracy: 0.6757 - val_loss: 0.9727 - val_accuracy: 0.6709\n","Epoch 44/150\n","138/138 [==============================] - 71s 515ms/step - loss: 0.8356 - accuracy: 0.6782 - val_loss: 0.9551 - val_accuracy: 0.6236\n","Epoch 45/150\n","138/138 [==============================] - 70s 508ms/step - loss: 0.8109 - accuracy: 0.6902 - val_loss: 0.8683 - val_accuracy: 0.6836\n","Epoch 46/150\n","138/138 [==============================] - 70s 510ms/step - loss: 0.8008 - accuracy: 0.6893 - val_loss: 1.1286 - val_accuracy: 0.6436\n","Epoch 47/150\n","138/138 [==============================] - 71s 515ms/step - loss: 0.7982 - accuracy: 0.6932 - val_loss: 1.0006 - val_accuracy: 0.6164\n","Epoch 48/150\n","138/138 [==============================] - 71s 515ms/step - loss: 0.7906 - accuracy: 0.6959 - val_loss: 1.0518 - val_accuracy: 0.5418\n","Epoch 49/150\n","130/138 [===========================>..] - ETA: 3s - loss: 0.7906 - accuracy: 0.6899"]}]},{"cell_type":"code","source":["y_pred = model.predict(test_generator)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = test_generator.classes\n","\n","print(classification_report(y_true_classes, y_pred_classes))"],"metadata":{"id":"_QCLXIZcTyct","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693202507710,"user_tz":-540,"elapsed":603,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"a25a76b9-ee4f-473d-8970-742eddc5d43e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["18/18 [==============================] - 0s 2ms/step\n","              precision    recall  f1-score   support\n","\n","           0       0.43      0.15      0.22        41\n","           1       0.82      0.63      0.71        99\n","           2       0.70      0.44      0.54       101\n","           3       0.72      0.93      0.81       309\n","\n","    accuracy                           0.72       550\n","   macro avg       0.67      0.53      0.57       550\n","weighted avg       0.71      0.72      0.70       550\n","\n"]}]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('72.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7f5CnkuvE2g","executionInfo":{"status":"ok","timestamp":1693202560336,"user_tz":-540,"elapsed":7443,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"7183ee6a-4113-42c6-96b5-d1e77feedd93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","source":["combined_df = pd.concat([pd.DataFrame(resized_images), metadata_df.drop(columns='lesions')], axis=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"2CiVGFj7bjdH","executionInfo":{"status":"error","timestamp":1693202567153,"user_tz":-540,"elapsed":1042,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"f1c5ede8-3fca-4003-cbd3-a8d6fbc2af2b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-0a3ba5c7fd9c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lesions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_on_sanitize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Must pass 2-d input. shape={values.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(5500, 96, 96, 3)"]}]},{"cell_type":"code","source":["train_images, test_images, train_labels, test_labels = train_test_split(combined_df, encoded_labels, test_size=0.2, random_state=42)\n","test_images, val_images, test_labels, val_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=42)"],"metadata":{"id":"xZO2cyEhYavU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history2 = model.fit(train_images, train_labels, epochs=150, batch_size=32, validation_data=(val_images, val_labels))"],"metadata":{"id":"ig6GvlEyYaqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(test_images)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(test_labels, axis=1)\n","\n","print(classification_report(y_true_classes, y_pred_classes))"],"metadata":{"id":"tm9LepXEYalM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78TBbsaKGM3x"},"outputs":[],"source":["polygon_binary_masks = create_polygon_binary_masks(image_data[:5], polygon_data[:5])"]},{"cell_type":"code","source":["def visualize_binary_masks(mask_list, selected_indices, figsize=(10, 5)):\n","    for idx in selected_indices:\n","        mask = mask_list[idx]\n","\n","        plt.figure(figsize=figsize)\n","        plt.imshow(mask, cmap='gray')\n","        plt.title(\"Binary Mask\")\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","# 예시 데이터\n","selected_indices = [0, 5, 10]  # 선택한 이미지 인덱스 리스트\n","\n","# 시각화\n","visualize_binary_masks(polygon_binary_masks, selected_indices)"],"metadata":{"id":"-seWfV2QHe7l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["polygon_data[:2]"],"metadata":{"id":"-PjjdmDhGYZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_data[:2]"],"metadata":{"id":"aDdhTMawGce4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLMFD5LYP8pk"},"outputs":[],"source":["polygon_binary_masks = [mask_map[..., 0] for mask_map in masks_maps]"]},{"cell_type":"code","source":["polygon_binary_masks = combine_images_and_masks(image_data, polygon_binary_masks)"],"metadata":{"id":"RaURtFgMhFGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize_masked_images(image_data, polygon_binary_masks, selected_indices=[0, 5, 10])"],"metadata":{"id":"DtwjT8yi7i-X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resized_images = resize_images(image_data, 96, 96)\n","normalized_images = normalize_images(resized_images)"],"metadata":{"id":"15aWNoYj_dvB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images, test_images, train_labels, test_labels = train_test_split(resized_images, encoded_labels, test_size=0.3, random_state=42)\n","test_images, val_images, test_labels, val_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=42)"],"metadata":{"id":"w6sbpH4i8RKG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_images, train_labels, epochs=150, batch_size=32, validation_data=(val_images, val_labels))"],"metadata":{"id":"2s8KRbrc8V6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(test_images)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(test_labels, axis=1)\n","\n","print(classification_report(y_true_classes, y_pred_classes))"],"metadata":{"id":"HTpOxSfU8V3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["polygon_segmentation_maps = [mask_map[..., 1] for mask_map in masks_maps]"],"metadata":{"id":"_I7AVH-MisQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["polygon_segmentation_maps = combine_images_and_masks(image_data, polygon_segmentation_maps)"],"metadata":{"id":"kV6xJJQEicpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize_masked_images(image_data, polygon_segmentation_maps, selected_indices=[0, 5, 10])"],"metadata":{"id":"njj5HIdZ7F6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_binary_masks = [mask_map[..., 2] for mask_map in masks_maps]"],"metadata":{"id":"dy0te6AziVVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_binary_masks = combine_images_and_masks(image_data, box_binary_masks)"],"metadata":{"id":"osoJaVCxiVQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize_masked_images(image_data, box_binary_masks, selected_indices=[0, 5, 10])"],"metadata":{"id":"b-X8m4yF7GcB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_segmentation_maps = [mask_map[..., 3] for mask_map in masks_maps]"],"metadata":{"id":"9AiDr1RPiVMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_segmentation_maps = combine_images_and_masks(image_data, box_segmentation_maps)"],"metadata":{"id":"N84mIlfpimqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize_masked_images(image_data, box_segmentation_maps, selected_indices=[0, 5, 10])"],"metadata":{"id":"vvJ0nGan7G8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MWhZQ90GMyH"},"outputs":[],"source":["original_size_mask_maps = resize_images(masks_maps, 96, 96)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YiVFErvYGMs5"},"outputs":[],"source":["resized_mask_maps = create_mask_maps(resize_images(image_data, 96, 96), polygon_data, box_data)"]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"ToP0SXs0Tz_m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# microscope cat"],"metadata":{"id":"5St-XgMdS3A_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZOVWv80Sea6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG-vxlAj_HYD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0qJBmnqSbr7"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","mount_file_id":"1Dnsl078JzGwH-snRqYpe4v_RDBNGZeJb","authorship_tag":"ABX9TyMvpDko9Wq/jGgW1pKJUumc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}