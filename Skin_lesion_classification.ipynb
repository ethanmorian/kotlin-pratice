{"cells":[{"cell_type":"markdown","metadata":{"id":"SoOMF4kHSwMS"},"source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2905,"status":"ok","timestamp":1692771996529,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"EzLpCjbDOZy_","outputId":"946d959d-5694-4b2b-855a-782b78f74602"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"sALkX2o9Syb_"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1184,"status":"ok","timestamp":1692772074398,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"fRfHAxbnUa_b"},"outputs":[],"source":["import cv2\n","import glob\n","import json\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","import re\n","import pandas as pd\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692772075183,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"i7jwMMug2YXB"},"outputs":[],"source":["def get_image_and_json_paths(src_path):\n","    image_paths = sorted(glob.glob(os.path.join(src_path, '**', '*.jpg'), recursive=True))\n","    json_paths = sorted(glob.glob(os.path.join(src_path, '**', '*.json'), recursive=True))\n","\n","    return image_paths, json_paths\n","\n","\n","def get_image_data(image_paths):\n","    return [cv2.imread(image_path) for image_path in tqdm(image_paths, desc='Loading Images')]\n","\n","\n","def extract_metadata_and_locations_from_json(json_paths):\n","    meta_data, polygon_data, box_data = [], [], []\n","    for json_path in tqdm(json_paths, desc='Loading JSON', unit=' file'):\n","        try:\n","            with open(json_path, \"r\", encoding=\"utf-8\") as file:\n","                json_data = json.loads(re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', file.read()))\n","                labeling_info, metadata = json_data['labelingInfo'], json_data.get('metaData', None)\n","\n","                filtered_metadata = {\n","                    'breed': metadata.get('breed', None),\n","                    'age': metadata.get('age', None),\n","                    'gender': metadata.get('gender', None),\n","                    'region': metadata.get('region', None),\n","                    'lesions': metadata.get('lesions', None)\n","                }\n","\n","                for entry in labeling_info:\n","                    if 'polygon' in entry:\n","                        polygon_data.append(entry['polygon'].get('location', None))\n","                    if 'box' in entry:\n","                        box_data.append(entry['box'].get('location', None))\n","\n","                meta_data.append(filtered_metadata)\n","        except Exception as e:\n","            print(f\"Error occurred while processing file: {json_path}\")\n","            print(f\"Error message: {e}\")\n","\n","    return meta_data, polygon_data, box_data\n","\n","\n","def create_mask_maps(image_data, polygon_data, box_data):\n","    mask_maps = []\n","\n","    for image in tqdm(image_data, desc='Generating Mask Maps for Each Image'):\n","        mask_map = np.zeros(image.shape[:2] + (4,), dtype=np.uint8)\n","        fill_value = 1\n","\n","        for entry in polygon_data:\n","            if 'polygon' in entry:\n","                loc = entry['polygon']['location']\n","                if loc:\n","                    loc_array = [[coord['x'], coord['y']] for coord in loc]\n","                    polygon_points = np.array(loc_array, np.int32).reshape((-1, 1, 2))\n","                    cv2.fillPoly(mask_map[..., 0], [polygon_points], 255)\n","                    cv2.fillPoly(mask_map[..., 1], [polygon_points], fill_value)\n","\n","        for entry in box_data:\n","            if 'box' in entry:\n","                loc = entry['box']['location']\n","                if loc:\n","                    cv2.rectangle(mask_map[..., 2], tuple(loc[:2]), tuple(loc[2:]), 255, thickness=-1)\n","                    cv2.rectangle(mask_map[..., 3], tuple(loc[:2]), tuple(loc[2:]), fill_value, thickness=-1)\n","\n","        mask_maps.append(mask_map)\n","\n","    return mask_maps\n","\n","\n","def combine_images_and_masks(image_list, mask_list):\n","    combined_images = []\n","\n","    for i in tqdm(range(len(image_list)), desc='Combining Images and Masks'):\n","        image = image_list[i]\n","        mask = mask_list[i]\n","\n","        combined_image = np.concatenate([image, mask[:, :, np.newaxis]], axis=-1)\n","        combined_images.append(combined_image)\n","\n","    return combined_images\n","\n","\n","def resize_images(images, width, height):\n","    return [cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA) for image in tqdm(images, desc='Resizing Images')]"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1692772079047,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"yH2t11ewBsJe"},"outputs":[],"source":["src_path = \"/content/drive/Shareddrives/반려묘\""]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17731,"status":"ok","timestamp":1692772111506,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"8tKyLk1IGIEw"},"outputs":[],"source":["image_paths, json_paths = get_image_and_json_paths(src_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4068556,"status":"ok","timestamp":1692776180056,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"XTJXZ1I1GR8N","outputId":"9bae8b0d-c2f2-4114-9315-6578505dfc72"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading Images: 100%|██████████| 5500/5500 [1:07:48<00:00,  1.35it/s]\n"]}],"source":["image_data = get_image_data(image_paths)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2426208,"status":"ok","timestamp":1692778606230,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"_EHfOaAWGRRY","outputId":"6690c2a5-14d4-4a19-972a-d1e99c41b143"},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading JSON:  55%|█████▍    | 3000/5500 [22:51<21:51,  1.91 file/s]"]},{"output_type":"stream","name":"stdout","text":["Error occurred while processing file: /content/drive/Shareddrives/반려묘/유증상/A2_비듬_각질_상피성잔고리/IMG_C_A2_000020.json\n","Error message: Expecting value: line 1 column 1 (char 0)\n"]},{"output_type":"stream","name":"stderr","text":["Loading JSON:  55%|█████▍    | 3017/5500 [22:52<05:19,  7.76 file/s]"]},{"output_type":"stream","name":"stdout","text":["Error occurred while processing file: /content/drive/Shareddrives/반려묘/유증상/A2_비듬_각질_상피성잔고리/IMG_C_A2_000028.json\n","Error message: Expecting value: line 1 column 1 (char 0)\n"]},{"output_type":"stream","name":"stderr","text":["Loading JSON: 100%|██████████| 5500/5500 [40:26<00:00,  2.27 file/s]\n"]}],"source":["meta_data, polygon_data, box_data = extract_metadata_and_locations_from_json(json_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78TBbsaKGM3x"},"outputs":[],"source":["masks_maps = create_mask_maps(image_data, polygon_data, box_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BLMFD5LYP8pk"},"outputs":[],"source":["polygon_binary_masks = [mask_map[..., 0] for mask_map in masks_maps]"]},{"cell_type":"code","source":["polygon_binary_masks = combine_images_and_masks(image_data, polygon_binary_masks)"],"metadata":{"id":"RaURtFgMhFGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_image_mask_properties(image_list, mask_list):\n","    for i in range(len(image_list)):\n","        image = image_list[i]\n","        mask = mask_list[i]\n","\n","        print(f\"Image {i + 1}:\")\n","        print(f\"  Image Shape: {image.shape}\")\n","        print(f\"  Mask Shape: {mask.shape}\")\n","\n","        if image.shape[:2] != mask.shape[:2]:\n","            print(\"  Image and mask shapes do not match!\")\n","\n","        if image.shape[2] != 3:\n","            print(\"  Image does not have 3 color channels!\")\n","\n","        if mask.shape[2] != 1:\n","            print(\"  Mask does not have 1 channel!\")\n","\n","        print()\n","\n","# 이미지와 마스크 데이터의 속성 확인\n","check_image_mask_properties(image_data, polygon_binary_masks)"],"metadata":{"id":"OD0cbG1pzCYt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["polygon_segmentation_maps = [mask_map[..., 1] for mask_map in masks_maps]"],"metadata":{"id":"_I7AVH-MisQL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["polygon_segmentation_maps = combine_images_and_masks(image_data, polygon_segmentation_maps)"],"metadata":{"id":"kV6xJJQEicpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_binary_masks = [mask_map[..., 2] for mask_map in masks_maps]"],"metadata":{"id":"dy0te6AziVVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_binary_masks = combine_images_and_masks(image_data, box_binary_masks)"],"metadata":{"id":"osoJaVCxiVQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_segmentation_maps = [mask_map[..., 3] for mask_map in masks_maps]"],"metadata":{"id":"9AiDr1RPiVMQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["box_segmentation_maps = combine_images_and_masks(image_data, box_segmentation_maps)"],"metadata":{"id":"N84mIlfpimqW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0MWhZQ90GMyH"},"outputs":[],"source":["original_size_mask_maps = resize_images(masks_maps, 96, 96)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YiVFErvYGMs5"},"outputs":[],"source":["resized_mask_maps = create_mask_maps(resize_images(image_data, 96, 96), polygon_data, box_data)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"MlalA8N-GMSd","executionInfo":{"status":"ok","timestamp":1692778878206,"user_tz":-540,"elapsed":632,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"outputs":[],"source":["metadata_df = pd.DataFrame(meta_data)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1692778880023,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"ZQ90HinzOLeE","outputId":"0537a882-6692-47fe-f414-bb102770c97f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       breed age gender region lesions\n","0      노르웨이숲  10      M      H      A7\n","1      노르웨이숲  10      M      B      A7\n","2      노르웨이숲   4      M      B      A7\n","3      노르웨이숲  10      F      B      A7\n","4      노르웨이숲  10      F      B      A7\n","...      ...  ..    ...    ...     ...\n","5493    페르시안   2      F      L      A6\n","5494  코리안숏헤어   8      F      H      A6\n","5495  코리안숏헤어   5      M      H      A6\n","5496  코리안숏헤어   2      F      H      A6\n","5497  코리안숏헤어   1      M      L      A6\n","\n","[5498 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-66f36e0c-e5c8-4da7-af4a-71f79de1eaba\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>breed</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>region</th>\n","      <th>lesions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>M</td>\n","      <td>H</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>노르웨이숲</td>\n","      <td>4</td>\n","      <td>M</td>\n","      <td>B</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>노르웨이숲</td>\n","      <td>10</td>\n","      <td>F</td>\n","      <td>B</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5493</th>\n","      <td>페르시안</td>\n","      <td>2</td>\n","      <td>F</td>\n","      <td>L</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>5494</th>\n","      <td>코리안숏헤어</td>\n","      <td>8</td>\n","      <td>F</td>\n","      <td>H</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>5495</th>\n","      <td>코리안숏헤어</td>\n","      <td>5</td>\n","      <td>M</td>\n","      <td>H</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>5496</th>\n","      <td>코리안숏헤어</td>\n","      <td>2</td>\n","      <td>F</td>\n","      <td>H</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>5497</th>\n","      <td>코리안숏헤어</td>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>L</td>\n","      <td>A6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5498 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66f36e0c-e5c8-4da7-af4a-71f79de1eaba')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-66f36e0c-e5c8-4da7-af4a-71f79de1eaba button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-66f36e0c-e5c8-4da7-af4a-71f79de1eaba');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-67a240e5-b212-4293-a1b4-1b796bddc5d4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67a240e5-b212-4293-a1b4-1b796bddc5d4')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-67a240e5-b212-4293-a1b4-1b796bddc5d4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":8}],"source":["metadata_df"]},{"cell_type":"markdown","metadata":{"id":"auDavqpSS5rc"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KN24A9E1JFc"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4QcwK9UBb2u"},"outputs":[],"source":["train_images, test_images, train_labels, test_labels = train_test_split(resize_images(image_data, 96, 96), metadata_df['lesions'], test_size=0.3, random_state=42)\n","test_images, val_images, test_labels, val_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZOVWv80Sea6"},"outputs":[],"source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# Conv2D 레이어와 MaxPooling2D 레이어 추가\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# Dropout 레이어 추가\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# Dense 레이어와 Dropout 레이어 추가\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","\n","# 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(val_images, val_labels))\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)\n","\n","# 분류 모델을 평가할 수 있는 다양한 지표 계산\n","y_pred = model.predict(test_images)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(test_labels, axis=1)\n","\n","# classification_report를 사용하여 분류 모델의 성능 평가\n","print(classification_report(y_true_classes, y_pred_classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG-vxlAj_HYD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0qJBmnqSbr7"},"outputs":[],"source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMPLQ5tbg/kXvIZEuZRrJ/Y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}