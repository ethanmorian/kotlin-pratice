{"cells":[{"cell_type":"markdown","metadata":{"id":"SoOMF4kHSwMS"},"source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2641,"status":"ok","timestamp":1692232692237,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"EzLpCjbDOZy_","outputId":"b918b170-6d47-42a8-e146-34398ba79e64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"sALkX2o9Syb_"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":832,"status":"ok","timestamp":1692249844920,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"i7jwMMug2YXB"},"outputs":[],"source":["import cv2\n","import glob\n","import json\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","import re\n","\n","def get_image_and_json_paths(src_path):\n","    image_paths = glob.glob(os.path.join(src_path, '**', '*.jpg'), recursive=True)\n","    image_paths.sort()\n","\n","    json_paths = glob.glob(os.path.join(src_path, '**', '*.json'), recursive=True)\n","    json_paths.sort()\n","\n","    return image_paths, json_paths\n","\n","\n","def get_image_data(image_paths):\n","    image_data = []\n","    for image_path in tqdm(image_paths, desc='Loading Images'):\n","        image = cv2.imread(image_path)\n","        image_data.append(image)\n","\n","    return image_data\n","\n","def get_data_info(json_paths):\n","    meta_data = []\n","    polygon_data = []\n","    box_data = []\n","\n","    for json_path in tqdm(json_paths, desc='Loading JSON', unit=' file'):\n","        try:\n","            with open(json_path, \"r\", encoding=\"utf-8\") as file:\n","                file_content = file.read()\n","                control_char_regex = r'[\\x00-\\x1F\\x7F-\\x9F]'\n","                cleaned_content = re.sub(control_char_regex, '', file_content)\n","                json_data = json.loads(cleaned_content)\n","                metadata = json_data.get('metaData', None)\n","\n","                filtered_metadata = {\n","                    'breed': metadata.get('breed', None),\n","                    'age': metadata.get('age', None),\n","                    'gender': metadata.get('gender', None),\n","                    'region': metadata.get('region', None),\n","                    'species': metadata.get('species', None),\n","                    'lesions': metadata.get('lesions', None),\n","                    'polygon_location': [],\n","                    'box_location': []\n","                }\n","\n","                labeling_info = json_data.get('labelingInfo', [])\n","\n","                for entry in labeling_info:\n","                    if 'polygon' in entry:\n","                        polygon_metadata = filtered_metadata.copy()\n","                        polygon_metadata['polygon_location'] = entry['polygon'].get('location', None)\n","                        polygon_data.append(polygon_metadata)\n","                    if 'box' in entry:\n","                        box_metadata = filtered_metadata.copy()\n","                        box_metadata['box_location'] = entry['box'].get('location', None)\n","                        box_data.append(box_metadata)\n","\n","                meta_data.append(filtered_metadata)\n","\n","        except json.JSONDecodeError as e:\n","            print(f\"Error decoding: {json_path} - {e}\")\n","\n","    return meta_data, polygon_data, box_data\n","\n","def resize_image(image, width, height):\n","    tqdm.write(f'Resizing image from {image.shape[:2]} to {(width, height)}')\n","    resized_image = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n","    return resized_image\n","\n","def create_masks_maps(image, polygon_info, box_info):\n","    masks_map = np.zeros(image.shape[:2] + (4,), dtype=np.uint8)\n","\n","    for entry in tqdm(polygon_info, desc='Drawing Polygon'):\n","        loc = entry.get('polygon_location', [])\n","        fill_value = entry.get('lesions', 0) + 1\n","        if loc:\n","            polygon_points = np.array(loc, np.int32).reshape((-1, 1, 2))\n","            cv2.fillPoly(masks_map[..., 0], [polygon_points], 255)\n","            cv2.fillPoly(masks_map[..., 1], [polygon_points], fill_value)\n","\n","    for entry in tqdm(box_info, desc='Drawing Box'):\n","        loc = entry.get('box_location', [])\n","        fill_value = entry.get('lesions', 0) + 1\n","        if loc:\n","            cv2.rectangle(masks_map[..., 2], tuple(loc[:2]), tuple(loc[2:]), 255, thickness=-1)\n","            cv2.rectangle(masks_map[..., 3], tuple(loc[:2]), tuple(loc[2:]), fill_value, thickness=-1)\n","\n","    return masks_map\n","\n","def generate_masks_maps(image_data, polygon_data, box_data):\n","    masks_maps = []\n","    for data in tqdm(zip(image_data, polygon_data, box_data), desc='Generating Masks Maps'):\n","        masks_map = create_masks_maps(*data)\n","        masks_maps.append(masks_map)\n","    return masks_maps"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":450,"status":"ok","timestamp":1692249851837,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"yH2t11ewBsJe"},"outputs":[],"source":["src_path = \"/content/drive/Shareddrives/152.반려동물 피부질환 데이터/validation/반려견\""]},{"cell_type":"code","source":["image_paths, json_paths = get_image_and_json_paths(src_path)"],"metadata":{"id":"y7aNuYeym11Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"elapsed":18,"status":"error","timestamp":1692232692237,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"kPE87bIUBtra","outputId":"7157e751-5590-4031-cd6a-30d5b938969a"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-df8a8a8d5a7d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'get_image_data' is not defined"]}],"source":["image_data = get_image_data(image_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_mElvZXYBu9M","outputId":"c16d4f43-7d47-4ace-b790-36f4dbe9e4b6"},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading JSON:   4%|▍         | 1748/40283 [04:46<00:59, 650.88 file/s]"]},{"name":"stdout","output_type":"stream","text":["Error decoding: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/validation/반려견/무증상/A1_구진_플라크/IMG_D_A7_242015.json - Expecting value: line 1 column 1 (char 0)\n"]},{"name":"stderr","output_type":"stream","text":["Loading JSON:  23%|██▎       | 9246/40283 [1:07:29<3:46:34,  2.28 file/s]\n"]},{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0c347272566f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolygon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-d81916175efa>\u001b[0m in \u001b[0;36mget_data_info\u001b[0;34m(src_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjson_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loading JSON'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mcontrol_char_regex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'[\\x00-\\x1F\\x7F-\\x9F]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/152.반려동물 피부질환 데이터/validation/반려견/무증상/A2_비듬_각질_상피성잔고리/IMG_D_A7_307572.json'"]}],"source":["meta_data, polygon_data, box_data = get_data_info(json_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qM9RIIj2Bv66"},"outputs":[],"source":["masks_maps = generate_masks_maps(image_data, polygon_data, box_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zPJEzzCuVy0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsVelS76GYKV"},"outputs":[],"source":["Before_Resize_Polygon_Binary_Mask.csv\n","After_Resize_Polygon_Binary_Mask.csv\n","Before_Resize_Box_Binary_Mask.csv\n","After_Resize_Box_Binary_Mask.csv\n","Before_Resize_Polygon_Segmentation_Map.csv\n","After_Resize_Polygon_Segmentation_Map.csv\n","Before_Resize_Box_Segmentation_Map.csv\n","After_Resize_Box_Segmentation_Map.csv\n","Before_Resize_Polygon_Box_Binary_Mask.csv\n","After_Resize_Polygon_Box_Binary_Mask.csv\n","Before_Resize_Polygon_Box_Segmentation_Map.csv\n","After_Resize_Polygon_Box_Segmentation_Map.csv\n","Before_Resize_Polygon_Binary_Mask_MetaData.csv\n","After_Resize_Polygon_Binary_Mask_MetaData.csv\n","Before_Resize_Box_Binary_Mask_MetaData.csv\n","After_Resize_Box_Binary_Mask_MetaData.csv\n","Before_Resize_Polygon_Segmentation_Map_MetaData.csv\n","After_Resize_Polygon_Segmentation_Map_MetaData.csv\n","Before_Resize_Box_Segmentation_Map_MetaData.csv\n","After_Resize_Box_Segmentation_Map_MetaData.csv"]},{"cell_type":"markdown","metadata":{"id":"auDavqpSS5rc"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KN24A9E1JFc"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4QcwK9UBb2u"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eK7BGzioShjF"},"outputs":[],"source":["# 분류 모델과 하이퍼파라미터를 설정합니다\n","model_LR = LogisticRegression(random_state=9)\n","model_LDA = LinearDiscriminantAnalysis(solver='svd')\n","model_KNN = KNeighborsClassifier(n_neighbors=5)\n","model_DT = DecisionTreeClassifier(n_estimators=100)\n","model_RF = RandomForestClassifier(n_estimators=200, random_state=0)\n","model_GaussianNB = GaussianNB(var_smoothing=1e-09)\n","model_SVM = SVC(kernel='linear', C=1, random_state=0)\n","\n","# 분류 모델들을 리스트에 담습니다\n","models = [model_LR, model_LDA, model_KNN, model_DT, model_RF, model_GaussianNB, model_SVM]\n","\n","# 각 분류 모델을 학습시키고 예측 결과를 출력합니다\n","for model in models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    score = accuracy_score(y_test, y_pred)\n","    print(f\"{model.__class__.__name__}: {score}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KutoBNj2_Iuw"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZOVWv80Sea6"},"outputs":[],"source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# 첫번째 Conv2D 레이어\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# 첫번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 두번째 Conv2D 레이어\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 세번째 Conv2D 레이어\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 세번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# 첫번째 Dense 레이어\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.5))\n","\n","# 두번째 Dense 레이어: 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=val_data)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_data)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG-vxlAj_HYD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0qJBmnqSbr7"},"outputs":[],"source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyP/3FumxhMJJgm7FoaEGaWQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}