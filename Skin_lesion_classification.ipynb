{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPXhWCQZQPKySHrwYOJG8Kd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"],"metadata":{"id":"SoOMF4kHSwMS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzLpCjbDOZy_","executionInfo":{"status":"ok","timestamp":1691564876114,"user_tz":-540,"elapsed":3746,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"635ce495-d11d-45cd-9118-04918d74dc14"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"sALkX2o9Syb_"}},{"cell_type":"code","source":["import os\n","import glob\n","import json\n","import cv2\n","\n","def get_image_data(src_path):\n","    image_paths = glob.glob(os.path.join(src_path, '**', '*.jpg'), recursive=True)\n","    image_paths.sort()\n","    image_data = [cv2.imread(image_path) for image_path in image_paths]\n","    return image_data\n","\n","def get_meta_data(src_path):\n","    json_paths = glob.glob(os.path.join(src_path, '**', '*.json'), recursive=True)\n","    json_paths.sort()\n","\n","    meta_data = []\n","    for json_path in json_paths:\n","        with open(json_path, \"r\", encoding=\"utf-8\") as file:\n","            file_content = file.read()\n","            try:\n","                json_data = json.loads(file_content)\n","                meta_data.append(json_data.get('metaData', None))\n","            except json.JSONDecodeError as e:\n","                print(f\"Error: {str(e)}\")\n","                print(f\"Invalid JSON file content: {json_path}:\")\n","                print(file_content)\n","                print(\"\\n\")\n","\n","    return meta_data"],"metadata":{"id":"i7jwMMug2YXB","executionInfo":{"status":"ok","timestamp":1691565115376,"user_tz":-540,"elapsed":808,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["src_path = \"/content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘\"\n","# image_data = get_image_data(src_path)\n","meta_data = get_meta_data(src_path)[:5]"],"metadata":{"id":"NWRvnwgw2u8q","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2905e4c7-7348-4234-8ebe-584d8519a654"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: Expecting value: line 1 column 1 (char 0)\n","Invalid JSON file content: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017596.json:\n","\n","\n","\n","Error: Expecting value: line 1 column 1 (char 0)\n","Invalid JSON file content: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017597.json:\n","\n","\n","\n","Error: Expecting value: line 1 column 1 (char 0)\n","Invalid JSON file content: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017598.json:\n","\n","\n","\n","Error: Expecting value: line 1 column 1 (char 0)\n","Invalid JSON file content: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017599.json:\n","\n","\n","\n","Error: Expecting value: line 1 column 1 (char 0)\n","Invalid JSON file content: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017600.json:\n","\n","\n","\n","Error: Expecting value: line 1 column 1 (char 0)\n","Invalid JSON file content: /content/drive/Shareddrives/152.반려동물 피부질환 데이터/일반카메라1/validation/반려묘/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017601.json:\n","\n","\n","\n"]}]},{"cell_type":"code","source":["Before_Resize_Polygon_Binary_Mask.csv\n","After_Resize_Polygon_Binary_Mask.csv\n","Before_Resize_Box_Binary_Mask.csv\n","After_Resize_Box_Binary_Mask.csv\n","Before_Resize_Polygon_Segmentation_Map.csv\n","After_Resize_Polygon_Segmentation_Map.csv\n","Before_Resize_Box_Segmentation_Map.csv\n","After_Resize_Box_Segmentation_Map.csv\n","Before_Resize_Polygon_Box_Binary_Mask.csv\n","After_Resize_Polygon_Box_Binary_Mask.csv\n","Before_Resize_Polygon_Box_Segmentation_Map.csv\n","After_Resize_Polygon_Box_Segmentation_Map.csv\n","Before_Resize_Polygon_Binary_Mask_MetaData.csv\n","After_Resize_Polygon_Binary_Mask_MetaData.csv\n","Before_Resize_Box_Binary_Mask_MetaData.csv\n","After_Resize_Box_Binary_Mask_MetaData.csv\n","Before_Resize_Polygon_Segmentation_Map_MetaData.csv\n","After_Resize_Polygon_Segmentation_Map_MetaData.csv\n","Before_Resize_Box_Segmentation_Map_MetaData.csv\n","After_Resize_Box_Segmentation_Map_MetaData.csv"],"metadata":{"id":"CsVelS76GYKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"auDavqpSS5rc"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"9KN24A9E1JFc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. 폴리곤 크롭 이미지\n","polygon_cropped = pd.read_csv(\"polygon_cropped.csv\")\n","\n","# 2. 박스 크롭 이미지\n","box_cropped = pd.read_csv(\"box_cropped.csv\")\n","\n","# 3. 폴리곤 크롭 이미지, 박스 크롭 이미지\n","polygon_box_cropped = pd.read_csv(\"polygon_box_cropped.csv\")\n","\n","# 4. 폴리곤 크롭 이미지, 메타데이터\n","polygon_cropped_metadata = pd.read_csv(\"polygon_cropped_metadata.csv\")\n","\n","# 5. 박스 크롭 이미지, 메타데이터\n","box_cropped_metadata = pd.read_csv(\"box_cropped_metadata.csv\")\n","\n","# 6. 폴리곤 크롭 이미지, 박스 크롭 이미지, 메타데이터\n","polygon_box_cropped_metadata = pd.read_csv(\"polygon_box_cropped_metadata.csv\")"],"metadata":{"id":"0PNTCTkPz0gx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"s4QcwK9UBb2u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 분류 모델과 하이퍼파라미터를 설정합니다\n","model_LR = LogisticRegression(random_state=9)\n","model_LDA = LinearDiscriminantAnalysis(solver='svd')\n","model_KNN = KNeighborsClassifier(n_neighbors=5)\n","model_DT = DecisionTreeClassifier(n_estimators=100)\n","model_RF = RandomForestClassifier(n_estimators=200, random_state=0)\n","model_GaussianNB = GaussianNB(var_smoothing=1e-09)\n","model_SVM = SVC(kernel='linear', C=1, random_state=0)\n","\n","# 분류 모델들을 리스트에 담습니다\n","models = [model_LR, model_LDA, model_KNN, model_DT, model_RF, model_GaussianNB, model_SVM]\n","\n","# 각 분류 모델을 학습시키고 예측 결과를 출력합니다\n","for model in models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    score = accuracy_score(y_test, y_pred)\n","    print(f\"{model.__class__.__name__}: {score}\")"],"metadata":{"id":"eK7BGzioShjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KutoBNj2_Iuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# 첫번째 Conv2D 레이어\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# 첫번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 두번째 Conv2D 레이어\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 세번째 Conv2D 레이어\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 세번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# 첫번째 Dense 레이어\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.5))\n","\n","# 두번째 Dense 레이어: 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=val_data)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_data)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"IZOVWv80Sea6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EG-vxlAj_HYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"f0qJBmnqSbr7"},"execution_count":null,"outputs":[]}]}