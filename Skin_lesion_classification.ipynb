{"cells":[{"cell_type":"markdown","metadata":{"id":"SoOMF4kHSwMS"},"source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4079,"status":"ok","timestamp":1693464301994,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"EzLpCjbDOZy_","outputId":"8c7f99bf-ea1e-4afe-aa8e-b4d9ae730382"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import cv2\n","import glob\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import re\n","import tensorflow as tf\n","from sklearn.metrics import classification_report\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import models\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tqdm import tqdm"],"metadata":{"id":"491U9sI3TVVj","executionInfo":{"status":"ok","timestamp":1693464318946,"user_tz":-540,"elapsed":4243,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def get_image_and_json_paths(src_path, num_files):\n","    image_paths = []\n","    json_paths = []\n","\n","    for root, dirs, files in os.walk(src_path):\n","        for dir in dirs:\n","            dir_path = os.path.join(root, dir)\n","            image_paths.extend(sorted(glob.glob(os.path.join(dir_path, '*.jpg'))[:num_files]))\n","            json_paths.extend(sorted(glob.glob(os.path.join(dir_path, '*.json'))[:num_files]))\n","\n","    return image_paths, json_paths\n","\n","def extract_data_from_json(json_paths):\n","    lesions, polygon_locations, box_locations = [], [], []\n","    for json_path in tqdm(json_paths, desc='Loading JSON', unit=' file'):\n","        try:\n","            with open(json_path, 'r', encoding='utf-8') as file:\n","                json_data = json.loads(re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', file.read()))\n","                metadata, labeling_info = json_data.get('metaData', None), json_data['labelingInfo']\n","\n","                lesions.append(metadata.get('lesions', None))\n","\n","                for entry in labeling_info:\n","                    if 'polygon' in entry:\n","                        polygon_locations.extend(entry['polygon'].get('location', None))\n","                    if 'box' in entry:\n","                        box_locations.extend(entry['box'].get('location', None))\n","\n","        except Exception as e:\n","            print(json_path)\n","            print(e)\n","\n","    return lesions, polygon_locations, box_locations"],"metadata":{"id":"qEuSRFdOTKoU","executionInfo":{"status":"ok","timestamp":1693464318946,"user_tz":-540,"elapsed":3,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sALkX2o9Syb_"},"source":["# camera cat"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":936,"status":"ok","timestamp":1693464319880,"user":{"displayName":"이보원","userId":"15276212846060170538"},"user_tz":-540},"id":"yH2t11ewBsJe"},"outputs":[],"source":["main_folder_path = '/content/drive/Shareddrives/반려묘/일반카메라'\n","num_files_to_load = 500\n","\n","image_paths, json_paths = get_image_and_json_paths(main_folder_path, num_files_to_load)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_EHfOaAWGRRY","outputId":"63ab8f83-0772-4538-9683-9ff06fa7a831","executionInfo":{"status":"ok","timestamp":1693464323031,"user_tz":-540,"elapsed":3157,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Loading JSON: 100%|██████████| 5500/5500 [00:03<00:00, 1399.49 file/s]\n"]}],"source":["lesions, polygon_locations, box_locations = extract_data_from_json(json_paths)"]},{"cell_type":"code","source":["df = pd.DataFrame({'image_path': image_paths, 'lesion': lesions})\n","\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"Kr-yYQQRlxFE","executionInfo":{"status":"ok","timestamp":1693464323031,"user_tz":-540,"elapsed":5,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"b59255d5-97f7-4003-c459-b38186a73bcf"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             image_path lesion\n","0     /content/drive/Shareddrives/반려묘/일반카메라/유증상...     A6\n","1     /content/drive/Shareddrives/반려묘/일반카메라/유증상...     A6\n","2     /content/drive/Shareddrives/반려묘/일반카메라/유증상...     A6\n","3     /content/drive/Shareddrives/반려묘/일반카메라/유증상...     A6\n","4     /content/drive/Shareddrives/반려묘/일반카메라/유증상...     A6\n","...                                                 ...    ...\n","5495  /content/drive/Shareddrives/반려묘/일반카메라/무증상...     A7\n","5496  /content/drive/Shareddrives/반려묘/일반카메라/무증상...     A7\n","5497  /content/drive/Shareddrives/반려묘/일반카메라/무증상...     A7\n","5498  /content/drive/Shareddrives/반려묘/일반카메라/무증상...     A7\n","5499  /content/drive/Shareddrives/반려묘/일반카메라/무증상...     A7\n","\n","[5500 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-3dc487bb-071c-41c8-9fca-38f04dc91670\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_path</th>\n","      <th>lesion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/유증상...</td>\n","      <td>A6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5495</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>5496</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>5497</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>5498</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","      <td>A7</td>\n","    </tr>\n","    <tr>\n","      <th>5499</th>\n","      <td>/content/drive/Shareddrives/반려묘/일반카메라/무증상...</td>\n","      <td>A7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5500 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3dc487bb-071c-41c8-9fca-38f04dc91670')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3dc487bb-071c-41c8-9fca-38f04dc91670 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3dc487bb-071c-41c8-9fca-38f04dc91670');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-46a6f84f-820b-4604-be7b-1a042f0a958d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46a6f84f-820b-4604-be7b-1a042f0a958d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-46a6f84f-820b-4604-be7b-1a042f0a958d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["datagen = ImageDataGenerator(rescale=1.0/255)"],"metadata":{"id":"rCDslFuU79Ds","executionInfo":{"status":"ok","timestamp":1693464323031,"user_tz":-540,"elapsed":4,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n","val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"],"metadata":{"id":"O7m1-ZfmV-01","executionInfo":{"status":"ok","timestamp":1693464323031,"user_tz":-540,"elapsed":4,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train_generator = datagen.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='image_path',\n","    y_col='lesion',\n","    class_mode='categorical',\n","    target_size=(96, 96),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1IU9hs473GM","executionInfo":{"status":"ok","timestamp":1693464324346,"user_tz":-540,"elapsed":1319,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"f5645108-d04d-444b-e414-646568a138de"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4400 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["val_generator = datagen.flow_from_dataframe(\n","    dataframe=val_df,\n","    x_col='image_path',\n","    y_col='lesion',\n","    class_mode='categorical',\n","    target_size=(96, 96),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hS9LF1g3U3cu","executionInfo":{"status":"ok","timestamp":1693464324346,"user_tz":-540,"elapsed":9,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"d93cc25c-5432-4844-cf84-82d00661a6f6"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 550 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["test_generator = datagen.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='image_path',\n","    y_col='lesion',\n","    class_mode='categorical',\n","    target_size=(96, 96),\n","    shuffle=False\n",")"],"metadata":{"id":"mXLi75CKV3Mk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693464324346,"user_tz":-540,"elapsed":6,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"cab0841e-1ab3-4a1b-a12d-58907f4f8208"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 550 validated image filenames belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["model = models.Sequential()\n","\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(units=4, activation='softmax'))\n","\n","opt = Adam(learning_rate=0.001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])"],"metadata":{"id":"JGUbxOe3TxF0","executionInfo":{"status":"ok","timestamp":1693464326058,"user_tz":-540,"elapsed":1715,"user":{"displayName":"이보원","userId":"15276212846060170538"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["history1 = model.fit(\n","    train_generator,\n","    epochs=150,\n","    batch_size=64,\n","    validation_data=val_generator\n",")"],"metadata":{"id":"2iSRx9X0aFUi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4bddac4-668d-467e-c64c-52c8cfe8f346"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","138/138 [==============================] - 970s 7s/step - loss: 1.6749 - accuracy: 0.4577 - val_loss: 1.4209 - val_accuracy: 0.5364\n","Epoch 2/150\n","138/138 [==============================] - 66s 480ms/step - loss: 1.2256 - accuracy: 0.5536 - val_loss: 5.0312 - val_accuracy: 0.5273\n","Epoch 3/150\n","138/138 [==============================] - 67s 485ms/step - loss: 1.2017 - accuracy: 0.5691 - val_loss: 2.3499 - val_accuracy: 0.5109\n","Epoch 4/150\n","138/138 [==============================] - 67s 487ms/step - loss: 1.1463 - accuracy: 0.5745 - val_loss: 1.5886 - val_accuracy: 0.5273\n","Epoch 5/150\n","138/138 [==============================] - 66s 480ms/step - loss: 1.0979 - accuracy: 0.5909 - val_loss: 2.1535 - val_accuracy: 0.5145\n","Epoch 6/150\n","138/138 [==============================] - 66s 476ms/step - loss: 1.1112 - accuracy: 0.5930 - val_loss: 1.4360 - val_accuracy: 0.5200\n","Epoch 7/150\n","138/138 [==============================] - 67s 485ms/step - loss: 1.0159 - accuracy: 0.6166 - val_loss: 1.8509 - val_accuracy: 0.4691\n","Epoch 8/150\n","138/138 [==============================] - 65s 474ms/step - loss: 0.9913 - accuracy: 0.6268 - val_loss: 1.2392 - val_accuracy: 0.5582\n","Epoch 9/150\n","138/138 [==============================] - 65s 470ms/step - loss: 0.9490 - accuracy: 0.6284 - val_loss: 1.1746 - val_accuracy: 0.5891\n","Epoch 10/150\n","138/138 [==============================] - 66s 478ms/step - loss: 0.9334 - accuracy: 0.6455 - val_loss: 1.1167 - val_accuracy: 0.5927\n","Epoch 11/150\n","138/138 [==============================] - 67s 483ms/step - loss: 0.9249 - accuracy: 0.6375 - val_loss: 1.3645 - val_accuracy: 0.4873\n","Epoch 12/150\n","138/138 [==============================] - 66s 476ms/step - loss: 0.8737 - accuracy: 0.6641 - val_loss: 1.9884 - val_accuracy: 0.3636\n","Epoch 13/150\n","138/138 [==============================] - 67s 483ms/step - loss: 0.8315 - accuracy: 0.6866 - val_loss: 1.0111 - val_accuracy: 0.5800\n","Epoch 14/150\n","138/138 [==============================] - 64s 467ms/step - loss: 0.7921 - accuracy: 0.6848 - val_loss: 1.4350 - val_accuracy: 0.6200\n","Epoch 15/150\n","138/138 [==============================] - 65s 470ms/step - loss: 0.7790 - accuracy: 0.6977 - val_loss: 1.4622 - val_accuracy: 0.5036\n","Epoch 16/150\n","138/138 [==============================] - 66s 480ms/step - loss: 0.8000 - accuracy: 0.6884 - val_loss: 2.0411 - val_accuracy: 0.4982\n","Epoch 17/150\n","138/138 [==============================] - 67s 483ms/step - loss: 0.7576 - accuracy: 0.7059 - val_loss: 2.5554 - val_accuracy: 0.3673\n","Epoch 18/150\n","138/138 [==============================] - 67s 485ms/step - loss: 0.6936 - accuracy: 0.7280 - val_loss: 1.1318 - val_accuracy: 0.6018\n","Epoch 19/150\n","138/138 [==============================] - 66s 478ms/step - loss: 0.7173 - accuracy: 0.7175 - val_loss: 1.3063 - val_accuracy: 0.5436\n","Epoch 20/150\n","138/138 [==============================] - 67s 489ms/step - loss: 0.6282 - accuracy: 0.7532 - val_loss: 1.4377 - val_accuracy: 0.5800\n","Epoch 21/150\n","138/138 [==============================] - 65s 472ms/step - loss: 0.6700 - accuracy: 0.7457 - val_loss: 1.3133 - val_accuracy: 0.5745\n","Epoch 22/150\n","138/138 [==============================] - 65s 472ms/step - loss: 0.5794 - accuracy: 0.7761 - val_loss: 1.0826 - val_accuracy: 0.6491\n","Epoch 23/150\n","138/138 [==============================] - 66s 475ms/step - loss: 0.6497 - accuracy: 0.7489 - val_loss: 16.5207 - val_accuracy: 0.1982\n","Epoch 24/150\n","138/138 [==============================] - 64s 467ms/step - loss: 0.7150 - accuracy: 0.7216 - val_loss: 2.0344 - val_accuracy: 0.5109\n","Epoch 25/150\n","138/138 [==============================] - 65s 471ms/step - loss: 0.5801 - accuracy: 0.7798 - val_loss: 1.1941 - val_accuracy: 0.6055\n","Epoch 26/150\n","138/138 [==============================] - 64s 464ms/step - loss: 0.4858 - accuracy: 0.8134 - val_loss: 1.2290 - val_accuracy: 0.6236\n","Epoch 27/150\n","138/138 [==============================] - 65s 473ms/step - loss: 0.5073 - accuracy: 0.7977 - val_loss: 1.4077 - val_accuracy: 0.5945\n","Epoch 28/150\n","138/138 [==============================] - 64s 466ms/step - loss: 0.4513 - accuracy: 0.8266 - val_loss: 1.0965 - val_accuracy: 0.6509\n","Epoch 29/150\n","138/138 [==============================] - 66s 479ms/step - loss: 0.4355 - accuracy: 0.8357 - val_loss: 1.7504 - val_accuracy: 0.5000\n","Epoch 30/150\n","138/138 [==============================] - 65s 469ms/step - loss: 0.3869 - accuracy: 0.8534 - val_loss: 1.2544 - val_accuracy: 0.6218\n","Epoch 31/150\n","138/138 [==============================] - 66s 477ms/step - loss: 0.3363 - accuracy: 0.8757 - val_loss: 1.4285 - val_accuracy: 0.6309\n","Epoch 32/150\n","138/138 [==============================] - 66s 476ms/step - loss: 0.3616 - accuracy: 0.8648 - val_loss: 1.4164 - val_accuracy: 0.5800\n","Epoch 33/150\n"," 80/138 [================>.............] - ETA: 24s - loss: 0.3113 - accuracy: 0.8876"]}]},{"cell_type":"code","source":["y_pred = model.predict(test_generator)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = test_generator.classes\n","\n","print(classification_report(y_true_classes, y_pred_classes))"],"metadata":{"id":"_QCLXIZcTyct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('72.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7f5CnkuvE2g","executionInfo":{"status":"ok","timestamp":1693202560336,"user_tz":-540,"elapsed":7443,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"7183ee6a-4113-42c6-96b5-d1e77feedd93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from skimage.feature import greycomatrix\n","import h5py\n","\n","class ImageFeatureExtractor:\n","    def __init__(self, target_size=(96, 96)):\n","        self.target_size = target_size\n","\n","    def preprocess_image(self, image_path):\n","        image = cv2.imread(image_path)\n","        image = cv2.resize(image, self.target_size)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        return image\n","\n","    def extract_color_histogram(self, image):\n","        histogram = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n","        histogram = cv2.normalize(histogram, histogram).flatten()\n","        return histogram\n","\n","    def extract_hu_moments(self, image):\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","        moments = cv2.HuMoments(cv2.moments(gray_image)).flatten()\n","        return moments\n","\n","    def extract_haralick_texture(self, image):\n","        gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","        texture = greycomatrix(gray_image, distances=[1], angles=[0], symmetric=True, normed=True)\n","        haralick_features = np.mean(texture, axis=(0, 1, 2))\n","        return haralick_features\n","\n","    def extract_features(self, image_path):\n","        image = self.preprocess_image(image_path)\n","        color_histogram = self.extract_color_histogram(image)\n","        hu_moments = self.extract_hu_moments(image)\n","        haralick_texture = self.extract_haralick_texture(image)\n","        global_features = np.concatenate([color_histogram, hu_moments, haralick_texture])\n","        return global_features\n","\n","    def save_features_to_hdf5(self, features, lesions, output_path):\n","        with h5py.File(output_path, 'w') as f:\n","            f.create_dataset('features', data=features)\n","            f.create_dataset('lesions', data=lesions)\n","\n","# HDF5 파일로부터 데이터 읽어오기\n","def load_data_from_hdf5(file_path):\n","    with h5py.File(file_path, 'r') as f:\n","        features = f['features'][:]\n","        lesions = f['lesions'][:]\n","    return features, lesions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"2CiVGFj7bjdH","executionInfo":{"status":"error","timestamp":1693202567153,"user_tz":-540,"elapsed":1042,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"f1c5ede8-3fca-4003-cbd3-a8d6fbc2af2b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-0a3ba5c7fd9c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lesions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 )\n\u001b[1;32m    721\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prep_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_on_sanitize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Must pass 2-d input. shape={values.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(5500, 96, 96, 3)"]}]},{"cell_type":"code","source":["feature_extractor = ImageFeatureExtractor(target_size=(96, 96))\n","\n","features = []\n","for image_path in image_paths:\n","    image_features = feature_extractor.extract_features(image_path)\n","    features.append(image_features)\n","\n","features = np.array(features)\n","lesions = np.array(lesions)\n","\n","output_path = 'features.h5'\n","feature_extractor.save_features_to_hdf5(features, lesions, output_path)"],"metadata":{"id":"maXZ70DWYZwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hdf5_file_path = 'path_to_your_hdf5_file.hdf5'\n","\n","features, lesions = load_data_from_hdf5(hdf5_file_path)\n","\n","X_train, X_test, y_train, y_test = train_test_split(features, lesions, test_size=0.2, random_state=42)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"],"metadata":{"id":"EeLaIH1wZTsL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history2 = model.fit(X_train, X_test, epochs=150, batch_size=32, validation_data=(X_val, y_val))"],"metadata":{"id":"ig6GvlEyYaqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","y_true_classes = np.argmax(y_test, axis=1)\n","\n","print(classification_report(y_true_classes, y_pred_classes))"],"metadata":{"id":"tm9LepXEYalM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qqg4JHS0Y_yH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def combine_images_and_masks(image_list, mask_list):\n","    combined_images = []\n","\n","    for i in tqdm(range(len(image_list)), desc='Combining Images and Masks'):\n","        image = image_list[i]\n","        mask = mask_list[i]\n","\n","        mask_channel = np.zeros_like(image[:, :, 0], dtype=np.uint8)\n","\n","        mask_channel[mask == 1] = 255\n","\n","        combined_image = np.dstack((image, mask_channel))\n","\n","        combined_images.append(combined_image)\n","\n","    return combined_images\n","\n","def one_hot_encode_labels(labels):\n","    label_binarizer = LabelBinarizer()\n","    encoded_labels = label_binarizer.fit_transform(labels)\n","    return np.array(encoded_labels), label_binarizer\n","\n","def create_polygon_binary_masks(image_list, polygon_locations_list):\n","    binary_masks = []\n","\n","    for image, polygon_locations in tqdm(zip(image_list, polygon_locations_list), desc='Generating Binary Masks', total=len(image_list)):\n","        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n","\n","        for poly_coords in polygon_locations:\n","            if poly_coords:\n","                poly_points = []\n","                i = 1\n","                while f'x{i}' in poly_coords and f'y{i}' in poly_coords:\n","                    x = poly_coords[f'x{i}']\n","                    y = poly_coords[f'y{i}']\n","                    poly_points.append([x, y])\n","                    i += 1\n","                if len(poly_points) > 0:\n","                    poly_points = np.array(poly_points, dtype=np.int32)\n","                    cv2.fillPoly(mask, [poly_points], 255)\n","            print(poly_coords)\n","\n","        binary_masks.append(mask)\n","\n","    return binary_masks\n","\n","def visualize_masks(image_data, mask_data, selected_indices, figsize=(10, 5)):\n","    for idx in selected_indices:\n","        image = image_data[idx]\n","        mask_map = mask_data[idx]\n","\n","        plt.figure(figsize=figsize)\n","        plt.subplot(1, mask_map.shape[2] + 1, 1)\n","        plt.imshow(image)\n","        plt.title('Original Image')\n","\n","        for ch in range(mask_map.shape[2]):\n","            plt.subplot(1, mask_map.shape[2] + 1, ch + 2)\n","            plt.imshow(mask_map[:, :, ch], cmap='gray')\n","            plt.title(f'Channel {ch}')\n","\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"5BhTlrhC2uf8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# microscope cat"],"metadata":{"id":"5St-XgMdS3A_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZOVWv80Sea6"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG-vxlAj_HYD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0qJBmnqSbr7"},"outputs":[],"source":["from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import MeanSquaredError\n","from tensorflow.keras.layers import Concatenate, MaxPooling2D, BatchNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import concatenate\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.losses import mean_squared_error\n","\n","def inception_module(input_layer, filters):\n","    conv1x1 = Conv2D(filters[0], (1, 1), activation='relu')(input_layer)\n","    conv3x3_reduce = Conv2D(filters[1], (1, 1), activation='relu')(input_layer)\n","    conv3x3 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(conv3x3_reduce)\n","    conv5x5_reduce = Conv2D(filters[3], (1, 1), activation='relu')(input_layer)\n","    conv5x5 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(conv5x5_reduce)\n","    maxpool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_layer)\n","    maxpool_conv = Conv2D(filters[5], (1, 1), activation='relu')(maxpool)\n","    inception_output = Concatenate(axis=-1)([conv1x1, conv3x3, conv5x5, maxpool_conv])\n","    return inception_output\n","\n","# Input\n","input_shape = (128, 128, 3)\n","input_layer = Input(shape=input_shape)\n","\n","# Inception block\n","inception_output = inception_module(input_layer, filters=[64, 128, 192, 32, 96, 64])\n","inception_output = inception_module(inception_output, filters=[64, 128, 192, 32, 96, 64])\n","# Add more inception modules if needed\n","\n","# Primary Capsule layer\n","primary_capsules = Conv2D(32, (1, 1), activation='relu')(inception_output)\n","\n","# Higher Capsule layers\n","# (Add imperative routing mechanism layers here)\n","\n","# PReLU activation for routing\n","higher_capsules_prelu = PReLU()(higher_capsules)\n","\n","# Flatten and Fully Connected layers\n","capsule_flatten = Flatten()(higher_capsules_prelu)  # Flatten higher capsules\n","output_layer = Dense(2, activation='softmax')(capsule_flatten)  # Two capsules: parasitized and uninfected\n","\n","# Create the model\n","model = Model(inputs=input_layer, outputs=output_layer)\n","\n","# Compile the model with Adam optimizer and custom loss function\n","optimizer = Adam(learning_rate=0.007, beta_1=0.8)\n","loss_fn = custom_loss_function # Define the custom loss function as described in the paper\n","model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","mount_file_id":"1Dnsl078JzGwH-snRqYpe4v_RDBNGZeJb","authorship_tag":"ABX9TyM+pCHrEGWAAqs7HFI1ZFBo"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}