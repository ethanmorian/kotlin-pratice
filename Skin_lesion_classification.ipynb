{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1Dnsl078JzGwH-snRqYpe4v_RDBNGZeJb","authorship_tag":"ABX9TyMCYFIG3+o7rAyGFa0DXl7a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"],"metadata":{"id":"SoOMF4kHSwMS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzLpCjbDOZy_","executionInfo":{"status":"ok","timestamp":1690779880193,"user_tz":-540,"elapsed":8957,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"0ec39951-740a-41d0-e451-0df5db4ecbed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"sALkX2o9Syb_"}},{"cell_type":"code","source":["# 운영체제 및 파일 시스템 관련\n","import os\n","import glob\n","\n","# JSON 처리\n","import json\n","\n","# 이미지 처리\n","from PIL import Image\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","\n","# 머신 러닝 모델\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","\n","# 딥 러닝 모델 (텐서플로)\n","import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n"],"metadata":{"id":"H1VHik52zEtk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_paths(root_directory, extension):\n","\n","    paths = []\n","\n","    for path in glob.glob(os.path.join(root_directory, '**', extension), recursive=True):\n","        paths.append(path)\n","\n","    paths.sort()\n","\n","    return paths\n","\n","\n","def read_json_metadata(json_path):\n","    with open(json_path, 'r') as f:\n","        json_data = json.load(f)\n","\n","    meta_data = json_data['metaData']\n","    return meta_data\n","    # metadata를 읽어와서 반환하는 함수\n","\n","\n","def get_polygon_and_box_coordinates(json_path):\n","    with open(json_path, 'r') as f:\n","        json_data = json.load(f)\n","\n","    labeling_info = json_data['labelingInfo']\n","    polygon_coordinates = []\n","    box_location = []\n","\n","    for item in labeling_info:\n","        if 'polygon' in item:\n","            polygon = item['polygon']\n","            location = polygon['location'][0]\n","            num_coordinates = len(location) // 2\n","            coordinates = [(location[f'x{i+1}'], location[f'y{i+1}']) for i in range(num_coordinates)]\n","            polygon_coordinates.append(coordinates)\n","            # 각각의 폴리곤 좌표를 다루는 코드\n","\n","        if 'box' in item:\n","            box = item['box']\n","            location = box['location'][0]\n","            x = location['x']\n","            y = location['y']\n","            width = location['width']\n","            height = location['height']\n","            box_location.append((x, y, width, height))\n","            # 박스 좌표를 다루는 코드\n","\n","    return polygon_coordinates, box_location\n","    # 폴리곤과 박스 좌표를 반환하는 함수\n","\n","\n","def crop_image_by_polygon(polygon_coordinates, image_path):\n","    image = Image.open(image_path)\n","    image_np = np.array(image)\n","    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n","\n","    mask = np.zeros(image_bgr.shape[:2], dtype=np.uint8)\n","    cv2.fillPoly(mask, [np.array(polygon_coordinates)], 255)\n","\n","    cropped_image = cv2.bitwise_and(image_bgr, image_bgr, mask=mask)\n","\n","    return cropped_image\n","    # 폴리곤 좌표에 따라 이미지를 잘라내는 함수\n","\n","\n","def crop_image_by_box(box_coordinate, image_path):\n","    x, y, width, height = box_coordinate\n","    image = Image.open(image_path)\n","    image_np = np.array(image)\n","    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)\n","\n","    cropped_image = image_bgr[y:y + height, x:x + width]\n","\n","    return cropped_image\n","    # 박스 좌표에 따라 이미지를 잘라내는 함수"],"metadata":{"id":"8MSlMCuCgOIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_extensions = '*.jpg'\n","json_extension = '*.json'\n","\n","root_directory = '/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘'\n","image_paths, json_paths = get_paths(root_directory, image_extensions), get_paths(root_directory, json_extension)"],"metadata":{"id":"Y7SQmwagYNHr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, j in zip(image_paths[:5], json_paths[:5]):\n","    print(i)\n","    print(j)\n","    print('='*50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LMKTjjuO4iMi","executionInfo":{"status":"ok","timestamp":1690791012459,"user_tz":-540,"elapsed":10,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"0f19d8a8-a192-4b26-e1d6-ed6b238fbb59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017282.jpg\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017282.json\n","==================================================\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017283.jpg\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017283.json\n","==================================================\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017284.jpg\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017284.json\n","==================================================\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017285.jpg\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017285.json\n","==================================================\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017286.jpg\n","/content/drive/Shareddrives/데이터230705/152.반려동물 피부질환 데이터/Validation/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리/IMG_C_A7_017286.json\n","==================================================\n"]}]},{"cell_type":"code","source":["read_json_metadata(json_paths[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDw5L0I7YVOE","executionInfo":{"status":"ok","timestamp":1690791019472,"user_tz":-540,"elapsed":931,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"b39d5d75-df4f-49da-f10c-fe07b4a56ac3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Raw data ID': 'IMG_C_A7_017282.jpg',\n"," 'copyrighter': '㈜미소정보기술',\n"," 'resolution': '1920X1080',\n"," 'date': '2021-12-15',\n"," 'breed': '코리안숏헤어',\n"," 'age': '6',\n"," 'gender': 'F',\n"," 'region': 'L',\n"," 'camera type': 'IMG',\n"," 'species': 'C',\n"," 'lesions': 'A7',\n"," 'diagnosis': '',\n"," 'Path': '무증상',\n"," 'identifier': '피부질환',\n"," 'src_path': '/라벨링데이터/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리',\n"," 'label_path': '/라벨링데이터/반려묘/피부/일반카메라/무증상/A2_비듬_각질_상피성잔고리',\n"," 'type': 'json',\n"," 'fileformat': 'jpg'}"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["cv2_imshow(cv2.imread(image_paths[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":761,"output_embedded_package_id":"1yuN49NWcY_mbKkmb3hEKFNOctkFE2Vjr"},"id":"ytgSLmMk22E-","executionInfo":{"status":"ok","timestamp":1690791034506,"user_tz":-540,"elapsed":13065,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"34d52b8b-8a83-4f1b-e982-3ee9520958f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"xn9z49K-CnXK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"auDavqpSS5rc"}},{"cell_type":"code","source":[],"metadata":{"id":"0PNTCTkPz0gx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 분류 모델과 하이퍼파라미터를 설정합니다\n","model_LR = LogisticRegression(random_state=9)\n","model_LDA = LinearDiscriminantAnalysis(solver='svd')\n","model_KNN = KNeighborsClassifier(n_neighbors=5)\n","model_DT = DecisionTreeClassifier(n_estimators=100)\n","model_RF = RandomForestClassifier(n_estimators=200, random_state=0)\n","model_GaussianNB = GaussianNB(var_smoothing=1e-09)\n","model_SVM = SVC(kernel='linear', C=1, random_state=0)\n","\n","# 분류 모델들을 리스트에 담습니다\n","models = [model_LR, model_LDA, model_KNN, model_DT, model_RF, model_GaussianNB, model_SVM]\n","\n","# 각 분류 모델을 학습시키고 예측 결과를 출력합니다\n","for model in models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    score = accuracy_score(y_test, y_pred)\n","    print(f\"{model.__class__.__name__}: {score}\")"],"metadata":{"id":"eK7BGzioShjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# 첫번째 Conv2D 레이어\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# 첫번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 두번째 Conv2D 레이어\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 세번째 Conv2D 레이어\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 세번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# 첫번째 Dense 레이어\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.5))\n","\n","# 두번째 Dense 레이어: 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=val_data)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_data)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"IZOVWv80Sea6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"f0qJBmnqSbr7"},"execution_count":null,"outputs":[]}]}