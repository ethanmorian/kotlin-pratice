{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNoodv/Vecmdfu0eGhwxfOe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Skin lesion classification of dermoscopic images using machine learning and convolutional neural network\n","\n","19 December 2022\n","\n","https://www.nature.com/articles/s41598-022-22644-9#Tab7\n","\n","https://aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=realm&dataSetSn=561"],"metadata":{"id":"SoOMF4kHSwMS"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzLpCjbDOZy_","executionInfo":{"status":"ok","timestamp":1690959297007,"user_tz":-540,"elapsed":6522,"user":{"displayName":"이보원","userId":"15276212846060170538"}},"outputId":"0e6af8be-8175-4db9-ecee-b8fc7ce7f1ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"sALkX2o9Syb_"}},{"cell_type":"code","source":["import os\n","import glob\n","import cv2\n","import json\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"JFDOiKrSqVJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디렉토리에서 이미지와 JSON 경로를 찾아 정렬된 순으로 반환\n","def get_image_and_json_paths(directory):\n","    image_paths = glob.glob(os.path.join(directory, '**', '*.jpg'), recursive=True)\n","    json_paths = glob.glob(os.path.join(directory, '**', '*.json'), recursive=True)\n","\n","    image_paths.sort()\n","    json_paths.sort()\n","\n","    return image_paths, json_paths\n","\n","\n","# 박스 또는 폴리곤 좌표에 따라 이미지를 크롭합니다. 좌표가 리스트 형태이면 폴리곤으로 간주하고, 그렇지 않으면 박스로 간주\n","def crop_image(image, coordinates):\n","    if isinstance(coordinates, list):  # 다각형\n","        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n","        cv2.fillPoly(mask, [np.array(coordinates, np.int32)], (255))\n","        rect = cv2.boundingRect(np.array(coordinates, np.int32))\n","        cropped_image = cv2.bitwise_and(image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]], image[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]], mask=mask[rect[1]:rect[1] + rect[3], rect[0]:rect[0] + rect[2]])\n","    else:  # 상자\n","        x, y, w, h = coordinates\n","        cropped_image = image[y:y + h, x:x + w]\n","    return cropped_image\n","\n","\n","# 크롭된 이미지를 주어진 target_size에 맞게 리사이징\n","def resize_image(image_data, target_size=(96, 96)):\n","    resized_image = cv2.resize(image_data, target_size, interpolation=cv2.INTER_LINEAR)\n","    return resized_image\n","\n","\n","# 이미지 경로와 JSON 경로를 전달 받아 이미지를 크롭하고 리사이징한 다음, 메타데이터를 포함한 데이터 프레임을 반환\n","def process_images(image_paths, json_paths):\n","    cropped_images = []\n","    metadata_list = []\n","\n","    for image_path, json_path in zip(image_paths, json_paths):\n","        with open(json_path) as f:\n","            json_data = json.load(f)\n","\n","        image = cv2.imread(image_path)\n","\n","        if json_data.get('metaData'):\n","            metadata_list.append(json_data['metaData'])\n","\n","        if json_data.get('labelingInfo'):\n","            for label_info in json_data['labelingInfo']:\n","                if label_info.get('box'):\n","                    coordinates = label_info['box']\n","                    cropped_image = crop_image(image, coordinates)\n","                    resized_cropped_image = resize_image(cropped_image)\n","                    cropped_images.append({\"cropped_box_image\": resized_cropped_image})\n","                if label_info.get('polygon'):\n","                    coordinates = label_info['polygon']\n","                    cropped_image = crop_image(image, coordinates)\n","                    resized_cropped_image = resize_image(cropped_image)\n","                    cropped_images.append({\"cropped_polygon_image\": resized_cropped_image})\n","\n","    metadata_df = pd.DataFrame(metadata_list)\n","    cropped_images_df = pd.concat([pd.DataFrame(cropped_images[i]) for i in range(len(cropped_images))], keys=cropped_images, axis=1)\n","    images_metadata_df = pd.concat([metadata_df, cropped_images_df], axis=1)\n","\n","    return images_metadata_df"],"metadata":{"id":"xn9z49K-CnXK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 및 JSON 파일이 포함된 디렉토리\n","src_path = '/content/drive/Shareddrives/152.반려동물 피부질환 데이터'\n","\n","image_paths, json_paths = get_image_and_json_paths(src_path)\n","result_df = process_images(image_paths, json_paths)\n","\n","result_df"],"metadata":{"id":"-DCSQAmMqUX6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메타데이터 개수 구하기\n","metadata_columns = len(result_df.columns) - 2\n","\n","# 1. 폴리곤 크롭 이미지\n","polygon_cropped = result_df.iloc[:, [-2]]\n","polygon_cropped.to_csv(\"polygon_cropped.csv\", index=False)\n","\n","# 2. 박스 크롭 이미지\n","box_cropped = result_df.iloc[:, [-1]]\n","box_cropped.to_csv(\"box_cropped.csv\", index=False)\n","\n","# 3. 폴리곤 크롭 이미지, 박스 크롭 이미지\n","polygon_box_cropped = result_df.iloc[:, [-2, -1]]\n","polygon_box_cropped.to_csv(\"polygon_box_cropped.csv\", index=False)\n","\n","# 4. 폴리곤 크롭 이미지, 메타데이터\n","polygon_cropped_metadata = result_df.iloc[:, list(range(metadata_columns)) + [-2]]\n","polygon_cropped_metadata.to_csv(\"polygon_cropped_metadata.csv\", index=False)\n","\n","# 5. 박스 크롭 이미지, 메타데이터\n","box_cropped_metadata = result_df.iloc[:, list(range(metadata_columns)) + [-1]]\n","box_cropped_metadata.to_csv(\"box_cropped_metadata.csv\", index=False)\n","\n","# 6. 폴리곤 크롭 이미지, 박스 크롭 이미지, 메타데이터\n","polygon_box_cropped_metadata = result_df.iloc[:, list(range(metadata_columns)) + [-2, -1]]\n","polygon_box_cropped_metadata.to_csv(\"polygon_box_cropped_metadata.csv\", index=False)"],"metadata":{"id":"1Q4RXaQOqUVh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modeling"],"metadata":{"id":"auDavqpSS5rc"}},{"cell_type":"code","source":[],"metadata":{"id":"9KN24A9E1JFc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. 폴리곤 크롭 이미지\n","polygon_cropped = pd.read_csv(\"polygon_cropped.csv\")\n","\n","# 2. 박스 크롭 이미지\n","box_cropped = pd.read_csv(\"box_cropped.csv\")\n","\n","# 3. 폴리곤 크롭 이미지, 박스 크롭 이미지\n","polygon_box_cropped = pd.read_csv(\"polygon_box_cropped.csv\")\n","\n","# 4. 폴리곤 크롭 이미지, 메타데이터\n","polygon_cropped_metadata = pd.read_csv(\"polygon_cropped_metadata.csv\")\n","\n","# 5. 박스 크롭 이미지, 메타데이터\n","box_cropped_metadata = pd.read_csv(\"box_cropped_metadata.csv\")\n","\n","# 6. 폴리곤 크롭 이미지, 박스 크롭 이미지, 메타데이터\n","polygon_box_cropped_metadata = pd.read_csv(\"polygon_box_cropped_metadata.csv\")"],"metadata":{"id":"0PNTCTkPz0gx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 분류 모델과 하이퍼파라미터를 설정합니다\n","model_LR = LogisticRegression(random_state=9)\n","model_LDA = LinearDiscriminantAnalysis(solver='svd')\n","model_KNN = KNeighborsClassifier(n_neighbors=5)\n","model_DT = DecisionTreeClassifier(n_estimators=100)\n","model_RF = RandomForestClassifier(n_estimators=200, random_state=0)\n","model_GaussianNB = GaussianNB(var_smoothing=1e-09)\n","model_SVM = SVC(kernel='linear', C=1, random_state=0)\n","\n","# 분류 모델들을 리스트에 담습니다\n","models = [model_LR, model_LDA, model_KNN, model_DT, model_RF, model_GaussianNB, model_SVM]\n","\n","# 각 분류 모델을 학습시키고 예측 결과를 출력합니다\n","for model in models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    score = accuracy_score(y_test, y_pred)\n","    print(f\"{model.__class__.__name__}: {score}\")"],"metadata":{"id":"eK7BGzioShjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KutoBNj2_Iuw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sequential 모델 생성\n","model = models.Sequential()\n","\n","# 첫번째 Conv2D 레이어\n","model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(96,96,3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(3, 3)))\n","\n","# 첫번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 두번째 Conv2D 레이어\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# 세번째 Conv2D 레이어\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# 세번째 Dropout 레이어\n","model.add(Dropout(0.25))\n","\n","# Flatten 레이어\n","model.add(Flatten())\n","\n","# 첫번째 Dense 레이어\n","model.add(Dense(units=1024, activation='relu'))\n","model.add(BatchNormalization())\n","\n","# 두번째 Dropout 레이어\n","model.add(Dropout(0.5))\n","\n","# 두번째 Dense 레이어: 최종 출력 레이어\n","model.add(Dense(units=7, activation='softmax'))\n","\n","# 모델 컴파일\n","opt = Adam(lr=0.001, decay=0.00001)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=opt,\n","              metrics=['accuracy'])\n","\n","# 모델 구조 요약\n","model.summary()\n","\n","# 모델 학습\n","epochs = 150\n","batch_size = 32\n","\n","history = model.fit(train_data, epochs=epochs, batch_size=batch_size, validation_data=val_data)\n","\n","# 모델 평가\n","test_loss, test_acc = model.evaluate(test_data)\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"IZOVWv80Sea6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EG-vxlAj_HYD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TensorFlow Lite 모델로 변환\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","# 변환된 모델을 파일로 저장\n","with open('your_model.tflite', 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"f0qJBmnqSbr7"},"execution_count":null,"outputs":[]}]}